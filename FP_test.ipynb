{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "020955e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T09:46:14.583648Z",
     "start_time": "2022-08-31T09:46:14.574074Z"
    }
   },
   "outputs": [],
   "source": [
    "import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "62734299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T09:53:54.551549Z",
     "start_time": "2022-08-31T09:53:54.544555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  0,   1,   2,   3,   4,   5],\n",
      "         [  6,   7,   8,   9,  10,  11],\n",
      "         [ 12,  13,  14,  15,  16,  17],\n",
      "         [ 18,  19,  20,  21,  22,  23],\n",
      "         [ 24,  25,  26,  27,  28,  29],\n",
      "         [ 30,  31,  32,  33,  34,  35]],\n",
      "\n",
      "        [[ 36,  37,  38,  39,  40,  41],\n",
      "         [ 42,  43,  44,  45,  46,  47],\n",
      "         [ 48,  49,  50,  51,  52,  53],\n",
      "         [ 54,  55,  56,  57,  58,  59],\n",
      "         [ 60,  61,  62,  63,  64,  65],\n",
      "         [ 66,  67,  68,  69,  70,  71]],\n",
      "\n",
      "        [[ 72,  73,  74,  75,  76,  77],\n",
      "         [ 78,  79,  80,  81,  82,  83],\n",
      "         [ 84,  85,  86,  87,  88,  89],\n",
      "         [ 90,  91,  92,  93,  94,  95],\n",
      "         [ 96,  97,  98,  99, 100, 101],\n",
      "         [102, 103, 104, 105, 106, 107]],\n",
      "\n",
      "        [[108, 109, 110, 111, 112, 113],\n",
      "         [114, 115, 116, 117, 118, 119],\n",
      "         [120, 121, 122, 123, 124, 125],\n",
      "         [126, 127, 128, 129, 130, 131],\n",
      "         [132, 133, 134, 135, 136, 137],\n",
      "         [138, 139, 140, 141, 142, 143]],\n",
      "\n",
      "        [[144, 145, 146, 147, 148, 149],\n",
      "         [150, 151, 152, 153, 154, 155],\n",
      "         [156, 157, 158, 159, 160, 161],\n",
      "         [162, 163, 164, 165, 166, 167],\n",
      "         [168, 169, 170, 171, 172, 173],\n",
      "         [174, 175, 176, 177, 178, 179]],\n",
      "\n",
      "        [[180, 181, 182, 183, 184, 185],\n",
      "         [186, 187, 188, 189, 190, 191],\n",
      "         [192, 193, 194, 195, 196, 197],\n",
      "         [198, 199, 200, 201, 202, 203],\n",
      "         [204, 205, 206, 207, 208, 209],\n",
      "         [210, 211, 212, 213, 214, 215]],\n",
      "\n",
      "        [[216, 217, 218, 219, 220, 221],\n",
      "         [222, 223, 224, 225, 226, 227],\n",
      "         [228, 229, 230, 231, 232, 233],\n",
      "         [234, 235, 236, 237, 238, 239],\n",
      "         [240, 241, 242, 243, 244, 245],\n",
      "         [246, 247, 248, 249, 250, 251]],\n",
      "\n",
      "        [[252, 253, 254, 255, 256, 257],\n",
      "         [258, 259, 260, 261, 262, 263],\n",
      "         [264, 265, 266, 267, 268, 269],\n",
      "         [270, 271, 272, 273, 274, 275],\n",
      "         [276, 277, 278, 279, 280, 281],\n",
      "         [282, 283, 284, 285, 286, 287]]])\n",
      "tensor([[  0,   1,   2,   6,   7,   8,  12,  13,  14,  36,  37,  38,  42,  43,\n",
      "          44,  48,  49,  50,  72,  73,  74,  78,  79,  80,  84,  85,  86, 108,\n",
      "         109, 110, 114, 115, 116, 120, 121, 122],\n",
      "        [  3,   4,   5,   9,  10,  11,  15,  16,  17,  39,  40,  41,  45,  46,\n",
      "          47,  51,  52,  53,  75,  76,  77,  81,  82,  83,  87,  88,  89, 111,\n",
      "         112, 113, 117, 118, 119, 123, 124, 125],\n",
      "        [ 18,  19,  20,  24,  25,  26,  30,  31,  32,  54,  55,  56,  60,  61,\n",
      "          62,  66,  67,  68,  90,  91,  92,  96,  97,  98, 102, 103, 104, 126,\n",
      "         127, 128, 132, 133, 134, 138, 139, 140],\n",
      "        [ 21,  22,  23,  27,  28,  29,  33,  34,  35,  57,  58,  59,  63,  64,\n",
      "          65,  69,  70,  71,  93,  94,  95,  99, 100, 101, 105, 106, 107, 129,\n",
      "         130, 131, 135, 136, 137, 141, 142, 143],\n",
      "        [144, 145, 146, 150, 151, 152, 156, 157, 158, 180, 181, 182, 186, 187,\n",
      "         188, 192, 193, 194, 216, 217, 218, 222, 223, 224, 228, 229, 230, 252,\n",
      "         253, 254, 258, 259, 260, 264, 265, 266],\n",
      "        [147, 148, 149, 153, 154, 155, 159, 160, 161, 183, 184, 185, 189, 190,\n",
      "         191, 195, 196, 197, 219, 220, 221, 225, 226, 227, 231, 232, 233, 255,\n",
      "         256, 257, 261, 262, 263, 267, 268, 269],\n",
      "        [162, 163, 164, 168, 169, 170, 174, 175, 176, 198, 199, 200, 204, 205,\n",
      "         206, 210, 211, 212, 234, 235, 236, 240, 241, 242, 246, 247, 248, 270,\n",
      "         271, 272, 276, 277, 278, 282, 283, 284],\n",
      "        [165, 166, 167, 171, 172, 173, 177, 178, 179, 201, 202, 203, 207, 208,\n",
      "         209, 213, 214, 215, 237, 238, 239, 243, 244, 245, 249, 250, 251, 273,\n",
      "         274, 275, 279, 280, 281, 285, 286, 287]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(8*6*6).reshape(8, 6, 6)\n",
    "block_size = [4, 3, 3]\n",
    "print(tensor)\n",
    "print(tensor.reshape(2, 4, 2, 3, 2, 3).permute(1, 3, 5, 0, 2, 4).reshape(4*3*3, -1).transpose(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c9bdab27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T09:53:20.431460Z",
     "start_time": "2022-08-31T09:53:20.424093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  0,   1,   2,   3,   4,   5],\n",
      "         [  6,   7,   8,   9,  10,  11],\n",
      "         [ 12,  13,  14,  15,  16,  17],\n",
      "         [ 18,  19,  20,  21,  22,  23],\n",
      "         [ 24,  25,  26,  27,  28,  29],\n",
      "         [ 30,  31,  32,  33,  34,  35]],\n",
      "\n",
      "        [[ 36,  37,  38,  39,  40,  41],\n",
      "         [ 42,  43,  44,  45,  46,  47],\n",
      "         [ 48,  49,  50,  51,  52,  53],\n",
      "         [ 54,  55,  56,  57,  58,  59],\n",
      "         [ 60,  61,  62,  63,  64,  65],\n",
      "         [ 66,  67,  68,  69,  70,  71]],\n",
      "\n",
      "        [[ 72,  73,  74,  75,  76,  77],\n",
      "         [ 78,  79,  80,  81,  82,  83],\n",
      "         [ 84,  85,  86,  87,  88,  89],\n",
      "         [ 90,  91,  92,  93,  94,  95],\n",
      "         [ 96,  97,  98,  99, 100, 101],\n",
      "         [102, 103, 104, 105, 106, 107]],\n",
      "\n",
      "        [[108, 109, 110, 111, 112, 113],\n",
      "         [114, 115, 116, 117, 118, 119],\n",
      "         [120, 121, 122, 123, 124, 125],\n",
      "         [126, 127, 128, 129, 130, 131],\n",
      "         [132, 133, 134, 135, 136, 137],\n",
      "         [138, 139, 140, 141, 142, 143]],\n",
      "\n",
      "        [[144, 145, 146, 147, 148, 149],\n",
      "         [150, 151, 152, 153, 154, 155],\n",
      "         [156, 157, 158, 159, 160, 161],\n",
      "         [162, 163, 164, 165, 166, 167],\n",
      "         [168, 169, 170, 171, 172, 173],\n",
      "         [174, 175, 176, 177, 178, 179]],\n",
      "\n",
      "        [[180, 181, 182, 183, 184, 185],\n",
      "         [186, 187, 188, 189, 190, 191],\n",
      "         [192, 193, 194, 195, 196, 197],\n",
      "         [198, 199, 200, 201, 202, 203],\n",
      "         [204, 205, 206, 207, 208, 209],\n",
      "         [210, 211, 212, 213, 214, 215]],\n",
      "\n",
      "        [[216, 217, 218, 219, 220, 221],\n",
      "         [222, 223, 224, 225, 226, 227],\n",
      "         [228, 229, 230, 231, 232, 233],\n",
      "         [234, 235, 236, 237, 238, 239],\n",
      "         [240, 241, 242, 243, 244, 245],\n",
      "         [246, 247, 248, 249, 250, 251]],\n",
      "\n",
      "        [[252, 253, 254, 255, 256, 257],\n",
      "         [258, 259, 260, 261, 262, 263],\n",
      "         [264, 265, 266, 267, 268, 269],\n",
      "         [270, 271, 272, 273, 274, 275],\n",
      "         [276, 277, 278, 279, 280, 281],\n",
      "         [282, 283, 284, 285, 286, 287]]])\n",
      "tensor([[  0,   1,   2,   6,   7,   8,  12,  13,  14,  36,  37,  38,  42,  43,\n",
      "          44,  48,  49,  50,  72,  73,  74,  78,  79,  80,  84,  85,  86, 108,\n",
      "         109, 110, 114, 115, 116, 120, 121, 122],\n",
      "        [  3,   4,   5,   9,  10,  11,  15,  16,  17,  39,  40,  41,  45,  46,\n",
      "          47,  51,  52,  53,  75,  76,  77,  81,  82,  83,  87,  88,  89, 111,\n",
      "         112, 113, 117, 118, 119, 123, 124, 125],\n",
      "        [ 18,  19,  20,  24,  25,  26,  30,  31,  32,  54,  55,  56,  60,  61,\n",
      "          62,  66,  67,  68,  90,  91,  92,  96,  97,  98, 102, 103, 104, 126,\n",
      "         127, 128, 132, 133, 134, 138, 139, 140],\n",
      "        [ 21,  22,  23,  27,  28,  29,  33,  34,  35,  57,  58,  59,  63,  64,\n",
      "          65,  69,  70,  71,  93,  94,  95,  99, 100, 101, 105, 106, 107, 129,\n",
      "         130, 131, 135, 136, 137, 141, 142, 143],\n",
      "        [144, 145, 146, 150, 151, 152, 156, 157, 158, 180, 181, 182, 186, 187,\n",
      "         188, 192, 193, 194, 216, 217, 218, 222, 223, 224, 228, 229, 230, 252,\n",
      "         253, 254, 258, 259, 260, 264, 265, 266],\n",
      "        [147, 148, 149, 153, 154, 155, 159, 160, 161, 183, 184, 185, 189, 190,\n",
      "         191, 195, 196, 197, 219, 220, 221, 225, 226, 227, 231, 232, 233, 255,\n",
      "         256, 257, 261, 262, 263, 267, 268, 269],\n",
      "        [162, 163, 164, 168, 169, 170, 174, 175, 176, 198, 199, 200, 204, 205,\n",
      "         206, 210, 211, 212, 234, 235, 236, 240, 241, 242, 246, 247, 248, 270,\n",
      "         271, 272, 276, 277, 278, 282, 283, 284],\n",
      "        [165, 166, 167, 171, 172, 173, 177, 178, 179, 201, 202, 203, 207, 208,\n",
      "         209, 213, 214, 215, 237, 238, 239, 243, 244, 245, 249, 250, 251, 273,\n",
      "         274, 275, 279, 280, 281, 285, 286, 287]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(8*6*6).reshape(8, 6, 6)\n",
    "block_size = [4, 3, 3]\n",
    "print(tensor)\n",
    "print(tensor.reshape(2, 4, 2, 3, 2, 3).permute(0, 2, 4, 1, 3 ,5).reshape(4*3*3, -1).transpose(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9bb9202c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T09:34:03.449508Z",
     "start_time": "2022-08-31T09:34:03.445481Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b7592861",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T09:34:20.923238Z",
     "start_time": "2022-08-31T09:34:20.919887Z"
    }
   },
   "outputs": [],
   "source": [
    "weight = torch.randn([16, 8, 32, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd7c2724",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-25T05:06:52.700042Z",
     "start_time": "2022-08-25T05:06:51.688165Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80582ade",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-25T05:06:54.078178Z",
     "start_time": "2022-08-25T05:06:54.074753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__name__', '__doc__', '__package__', '__loader__', '__spec__', '__path__', '__file__', '__cached__', '__builtins__', 'alexnet', 'AlexNet', 'resnet', 'ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'resnext50_32x4d', 'resnext101_32x8d', 'wide_resnet50_2', 'wide_resnet101_2', 'resnext', 'ResNeXt', 'resnext50', 'resnext101', 'resnext152', 'vgg', 'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'squeezenet', 'SqueezeNet', 'squeezenet1_0', 'squeezenet1_1', 'inception', 'Inception3', 'inception_v3', 'InceptionOutputs', '_InceptionOutputs', 'densenet', 'DenseNet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'googlenet', 'GoogLeNet', 'GoogLeNetOutputs', '_GoogLeNetOutputs', 'mobilenetv2', 'mobilenetv3', 'mobilenet', 'MobileNetV2', 'mobilenet_v2', 'MobileNetV3', 'mobilenet_v3_large', 'mobilenet_v3_small', 'mnasnet', 'MNASNet', 'mnasnet0_5', 'mnasnet0_75', 'mnasnet1_0', 'mnasnet1_3', 'shufflenetv2', 'ShuffleNetV2', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'shufflenet_v2_x1_5', 'shufflenet_v2_x2_0', 'efficientnet', 'EfficientNet', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'efficientnet_b3', 'efficientnet_b4', 'efficientnet_b5', 'efficientnet_b6', 'efficientnet_b7', '_utils', 'segmentation', 'detection', 'video', 'quantization', 'feature_extraction'])\n"
     ]
    }
   ],
   "source": [
    "print(models.__dict__.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3f56583",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-25T05:06:56.666102Z",
     "start_time": "2022-08-25T05:06:56.122912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get pretrained net :  resnet50\n"
     ]
    }
   ],
   "source": [
    "net_name = 'resnet50'\n",
    "\n",
    "if hasattr(models, net_name):\n",
    "    net = getattr(models, net_name)(pretrained=True)\n",
    "    print(f\"get pretrained net :  {net_name}\")\n",
    "else:\n",
    "    print(f\"model is not exist {net_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2635374d",
   "metadata": {},
   "source": [
    "## resnet18 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7120a9cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T01:43:12.721373Z",
     "start_time": "2022-08-26T01:43:12.611809Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): ConvBNActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_name = 'mobilenet_v2'\n",
    "net = getattr(models, net_name)(pretrained=True)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2bfc0914",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T01:44:50.794455Z",
     "start_time": "2022-08-26T01:44:50.003316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get pretrained net :  resnet18\n",
      "========================================\n",
      "conv1 layer's weight exponent bit count\n",
      "\n",
      "01011011 : 2\n",
      "01011100 : 2\n",
      "01011101 : 5\n",
      "01011110 : 7\n",
      "01011111 : 15\n",
      "01100000 : 21\n",
      "01100001 : 39\n",
      "01100010 : 121\n",
      "01100011 : 227\n",
      "01100100 : 163\n",
      "01100101 : 112\n",
      "01100110 : 87\n",
      "01100111 : 74\n",
      "01101000 : 59\n",
      "01101001 : 41\n",
      "01101010 : 84\n",
      "01101011 : 57\n",
      "01101100 : 32\n",
      "01101101 : 28\n",
      "01101110 : 1\n",
      "01101111 : 2\n",
      "01110000 : 5\n",
      "01110001 : 4\n",
      "01110010 : 12\n",
      "01110011 : 24\n",
      "01110100 : 66\n",
      "01110101 : 97\n",
      "01110110 : 221\n",
      "01110111 : 444\n",
      "01111000 : 854\n",
      "01111001 : 1410\n",
      "01111010 : 1687\n",
      "01111011 : 1545\n",
      "01111100 : 1213\n",
      "01111101 : 551\n",
      "01111110 : 93\n",
      "01111111 : 3\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer1.0.conv1 layer's weight exponent bit count\n",
      "\n",
      "01010111 : 1\n",
      "01011001 : 2\n",
      "01011010 : 2\n",
      "01011011 : 7\n",
      "01011100 : 12\n",
      "01011101 : 22\n",
      "01011110 : 39\n",
      "01011111 : 108\n",
      "01100000 : 167\n",
      "01100001 : 348\n",
      "01100010 : 595\n",
      "01100011 : 858\n",
      "01100100 : 640\n",
      "01100101 : 393\n",
      "01100110 : 332\n",
      "01100111 : 192\n",
      "01101000 : 210\n",
      "01101001 : 205\n",
      "01101010 : 200\n",
      "01101011 : 174\n",
      "01101100 : 72\n",
      "01101101 : 32\n",
      "01101110 : 17\n",
      "01101111 : 11\n",
      "01110000 : 18\n",
      "01110001 : 38\n",
      "01110010 : 105\n",
      "01110011 : 199\n",
      "01110100 : 386\n",
      "01110101 : 776\n",
      "01110110 : 1537\n",
      "01110111 : 2952\n",
      "01111000 : 5516\n",
      "01111001 : 8188\n",
      "01111010 : 7599\n",
      "01111011 : 3691\n",
      "01111100 : 1002\n",
      "01111101 : 200\n",
      "01111110 : 18\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer1.0.conv2 layer's weight exponent bit count\n",
      "\n",
      "01101010 : 1\n",
      "01101100 : 1\n",
      "01101101 : 2\n",
      "01101110 : 16\n",
      "01101111 : 15\n",
      "01110000 : 43\n",
      "01110001 : 44\n",
      "01110010 : 113\n",
      "01110011 : 235\n",
      "01110100 : 453\n",
      "01110101 : 935\n",
      "01110110 : 1723\n",
      "01110111 : 3443\n",
      "01111000 : 6481\n",
      "01111001 : 9606\n",
      "01111010 : 8950\n",
      "01111011 : 4051\n",
      "01111100 : 728\n",
      "01111101 : 24\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer1.1.conv1 layer's weight exponent bit count\n",
      "\n",
      "01101011 : 1\n",
      "01101100 : 2\n",
      "01101101 : 1\n",
      "01101110 : 6\n",
      "01101111 : 20\n",
      "01110000 : 26\n",
      "01110001 : 57\n",
      "01110010 : 100\n",
      "01110011 : 213\n",
      "01110100 : 471\n",
      "01110101 : 861\n",
      "01110110 : 1718\n",
      "01110111 : 3223\n",
      "01111000 : 6096\n",
      "01111001 : 9512\n",
      "01111010 : 9331\n",
      "01111011 : 4211\n",
      "01111100 : 901\n",
      "01111101 : 105\n",
      "01111110 : 9\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer1.1.conv2 layer's weight exponent bit count\n",
      "\n",
      "01101010 : 1\n",
      "01101101 : 3\n",
      "01101110 : 4\n",
      "01101111 : 18\n",
      "01110000 : 25\n",
      "01110001 : 45\n",
      "01110010 : 113\n",
      "01110011 : 218\n",
      "01110100 : 457\n",
      "01110101 : 884\n",
      "01110110 : 1759\n",
      "01110111 : 3449\n",
      "01111000 : 6291\n",
      "01111001 : 9805\n",
      "01111010 : 9243\n",
      "01111011 : 3870\n",
      "01111100 : 653\n",
      "01111101 : 26\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.0.conv1 layer's weight exponent bit count\n",
      "\n",
      "01100111 : 1\n",
      "01101010 : 3\n",
      "01101011 : 1\n",
      "01101100 : 10\n",
      "01101101 : 9\n",
      "01101110 : 13\n",
      "01101111 : 34\n",
      "01110000 : 67\n",
      "01110001 : 118\n",
      "01110010 : 259\n",
      "01110011 : 502\n",
      "01110100 : 962\n",
      "01110101 : 1899\n",
      "01110110 : 3875\n",
      "01110111 : 7414\n",
      "01111000 : 13735\n",
      "01111001 : 19943\n",
      "01111010 : 16852\n",
      "01111011 : 6893\n",
      "01111100 : 1095\n",
      "01111101 : 43\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.0.conv2 layer's weight exponent bit count\n",
      "\n",
      "01101001 : 1\n",
      "01101011 : 9\n",
      "01101100 : 15\n",
      "01101101 : 12\n",
      "01101110 : 32\n",
      "01101111 : 71\n",
      "01110000 : 141\n",
      "01110001 : 265\n",
      "01110010 : 545\n",
      "01110011 : 1118\n",
      "01110100 : 2250\n",
      "01110101 : 4625\n",
      "01110110 : 9031\n",
      "01110111 : 17360\n",
      "01111000 : 31793\n",
      "01111001 : 42408\n",
      "01111010 : 28689\n",
      "01111011 : 7928\n",
      "01111100 : 1104\n",
      "01111101 : 59\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.0.downsample.0 layer's weight exponent bit count\n",
      "\n",
      "01101100 : 1\n",
      "01101101 : 1\n",
      "01101110 : 1\n",
      "01101111 : 2\n",
      "01110000 : 2\n",
      "01110001 : 15\n",
      "01110010 : 16\n",
      "01110011 : 37\n",
      "01110100 : 81\n",
      "01110101 : 139\n",
      "01110110 : 352\n",
      "01110111 : 605\n",
      "01111000 : 1169\n",
      "01111001 : 1989\n",
      "01111010 : 2118\n",
      "01111011 : 1143\n",
      "01111100 : 401\n",
      "01111101 : 115\n",
      "01111110 : 5\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.1.conv1 layer's weight exponent bit count\n",
      "\n",
      "01100111 : 1\n",
      "01101001 : 2\n",
      "01101010 : 4\n",
      "01101011 : 5\n",
      "01101100 : 7\n",
      "01101101 : 11\n",
      "01101110 : 39\n",
      "01101111 : 56\n",
      "01110000 : 141\n",
      "01110001 : 280\n",
      "01110010 : 548\n",
      "01110011 : 1108\n",
      "01110100 : 2220\n",
      "01110101 : 4514\n",
      "01110110 : 8929\n",
      "01110111 : 17298\n",
      "01111000 : 30974\n",
      "01111001 : 42121\n",
      "01111010 : 29932\n",
      "01111011 : 8180\n",
      "01111100 : 1035\n",
      "01111101 : 51\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.1.conv2 layer's weight exponent bit count\n",
      "\n",
      "01100100 : 1\n",
      "01100111 : 1\n",
      "01101000 : 1\n",
      "01101001 : 3\n",
      "01101010 : 3\n",
      "01101011 : 5\n",
      "01101100 : 6\n",
      "01101101 : 16\n",
      "01101110 : 35\n",
      "01101111 : 85\n",
      "01110000 : 147\n",
      "01110001 : 270\n",
      "01110010 : 585\n",
      "01110011 : 1183\n",
      "01110100 : 2256\n",
      "01110101 : 4705\n",
      "01110110 : 9272\n",
      "01110111 : 17894\n",
      "01111000 : 32004\n",
      "01111001 : 43526\n",
      "01111010 : 28877\n",
      "01111011 : 6144\n",
      "01111100 : 429\n",
      "01111101 : 8\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.0.conv1 layer's weight exponent bit count\n",
      "\n",
      "01101000 : 1\n",
      "01101001 : 2\n",
      "01101010 : 6\n",
      "01101011 : 7\n",
      "01101100 : 22\n",
      "01101101 : 32\n",
      "01101110 : 81\n",
      "01101111 : 150\n",
      "01110000 : 325\n",
      "01110001 : 668\n",
      "01110010 : 1251\n",
      "01110011 : 2447\n",
      "01110100 : 5113\n",
      "01110101 : 10046\n",
      "01110110 : 20140\n",
      "01110111 : 38730\n",
      "01111000 : 67616\n",
      "01111001 : 86057\n",
      "01111010 : 50725\n",
      "01111011 : 10388\n",
      "01111100 : 1062\n",
      "01111101 : 43\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.0.conv2 layer's weight exponent bit count\n",
      "\n",
      "01100110 : 2\n",
      "01101000 : 3\n",
      "01101001 : 3\n",
      "01101010 : 13\n",
      "01101011 : 20\n",
      "01101100 : 40\n",
      "01101101 : 81\n",
      "01101110 : 154\n",
      "01101111 : 318\n",
      "01110000 : 705\n",
      "01110001 : 1388\n",
      "01110010 : 2841\n",
      "01110011 : 5441\n",
      "01110100 : 11239\n",
      "01110101 : 22389\n",
      "01110110 : 44275\n",
      "01110111 : 85146\n",
      "01111000 : 146328\n",
      "01111001 : 172304\n",
      "01111010 : 83565\n",
      "01111011 : 12557\n",
      "01111100 : 989\n",
      "01111101 : 23\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.0.downsample.0 layer's weight exponent bit count\n",
      "\n",
      "01101010 : 1\n",
      "01101011 : 1\n",
      "01101100 : 3\n",
      "01101101 : 2\n",
      "01101110 : 12\n",
      "01101111 : 11\n",
      "01110000 : 26\n",
      "01110001 : 53\n",
      "01110010 : 132\n",
      "01110011 : 273\n",
      "01110100 : 509\n",
      "01110101 : 983\n",
      "01110110 : 1997\n",
      "01110111 : 3873\n",
      "01111000 : 6878\n",
      "01111001 : 9562\n",
      "01111010 : 6538\n",
      "01111011 : 1729\n",
      "01111100 : 182\n",
      "01111101 : 3\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.1.conv1 layer's weight exponent bit count\n",
      "\n",
      "01100011 : 1\n",
      "01100101 : 1\n",
      "01100110 : 1\n",
      "01100111 : 2\n",
      "01101000 : 3\n",
      "01101001 : 4\n",
      "01101010 : 11\n",
      "01101011 : 29\n",
      "01101100 : 55\n",
      "01101101 : 112\n",
      "01101110 : 190\n",
      "01101111 : 359\n",
      "01110000 : 742\n",
      "01110001 : 1517\n",
      "01110010 : 3066\n",
      "01110011 : 5944\n",
      "01110100 : 12265\n",
      "01110101 : 24339\n",
      "01110110 : 47540\n",
      "01110111 : 91586\n",
      "01111000 : 154377\n",
      "01111001 : 169739\n",
      "01111010 : 69296\n",
      "01111011 : 8135\n",
      "01111100 : 505\n",
      "01111101 : 5\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.1.conv2 layer's weight exponent bit count\n",
      "\n",
      "01101000 : 6\n",
      "01101001 : 10\n",
      "01101010 : 8\n",
      "01101011 : 26\n",
      "01101100 : 52\n",
      "01101101 : 120\n",
      "01101110 : 197\n",
      "01101111 : 391\n",
      "01110000 : 851\n",
      "01110001 : 1640\n",
      "01110010 : 3220\n",
      "01110011 : 6548\n",
      "01110100 : 13035\n",
      "01110101 : 25965\n",
      "01110110 : 51069\n",
      "01110111 : 96654\n",
      "01111000 : 159167\n",
      "01111001 : 164299\n",
      "01111010 : 60690\n",
      "01111011 : 5642\n",
      "01111100 : 227\n",
      "01111101 : 7\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer4.0.conv1 layer's weight exponent bit count\n",
      "\n",
      "01100100 : 1\n",
      "01100110 : 2\n",
      "01100111 : 3\n",
      "01101000 : 3\n",
      "01101001 : 13\n",
      "01101010 : 31\n",
      "01101011 : 38\n",
      "01101100 : 107\n",
      "01101101 : 192\n",
      "01101110 : 436\n",
      "01101111 : 820\n",
      "01110000 : 1585\n",
      "01110001 : 3259\n",
      "01110010 : 6222\n",
      "01110011 : 12945\n",
      "01110100 : 25545\n",
      "01110101 : 51389\n",
      "01110110 : 101166\n",
      "01110111 : 193109\n",
      "01111000 : 321274\n",
      "01111001 : 338356\n",
      "01111010 : 114781\n",
      "01111011 : 8091\n",
      "01111100 : 275\n",
      "01111101 : 5\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer4.0.conv2 layer's weight exponent bit count\n",
      "\n",
      "01100101 : 2\n",
      "01100110 : 7\n",
      "01100111 : 7\n",
      "01101000 : 15\n",
      "01101001 : 33\n",
      "01101010 : 70\n",
      "01101011 : 107\n",
      "01101100 : 226\n",
      "01101101 : 427\n",
      "01101110 : 888\n",
      "01101111 : 1730\n",
      "01110000 : 3550\n",
      "01110001 : 7116\n",
      "01110010 : 14070\n",
      "01110011 : 28792\n",
      "01110100 : 57366\n",
      "01110101 : 114467\n",
      "01110110 : 225221\n",
      "01110111 : 426359\n",
      "01111000 : 685166\n",
      "01111001 : 632855\n",
      "01111010 : 153625\n",
      "01111011 : 6968\n",
      "01111100 : 222\n",
      "01111101 : 7\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer4.0.downsample.0 layer's weight exponent bit count\n",
      "\n",
      "01100110 : 1\n",
      "01101000 : 1\n",
      "01101001 : 1\n",
      "01101010 : 3\n",
      "01101011 : 5\n",
      "01101100 : 11\n",
      "01101101 : 13\n",
      "01101110 : 33\n",
      "01101111 : 57\n",
      "01110000 : 114\n",
      "01110001 : 228\n",
      "01110010 : 502\n",
      "01110011 : 974\n",
      "01110100 : 1936\n",
      "01110101 : 3941\n",
      "01110110 : 7792\n",
      "01110111 : 15094\n",
      "01111000 : 27115\n",
      "01111001 : 38177\n",
      "01111010 : 27673\n",
      "01111011 : 6760\n",
      "01111100 : 614\n",
      "01111101 : 25\n",
      "01111110 : 2\n",
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "layer4.1.conv1 layer's weight exponent bit count\n",
      "\n",
      "01100011 : 2\n",
      "01100101 : 2\n",
      "01100110 : 7\n",
      "01100111 : 9\n",
      "01101000 : 18\n",
      "01101001 : 38\n",
      "01101010 : 59\n",
      "01101011 : 100\n",
      "01101100 : 214\n",
      "01101101 : 423\n",
      "01101110 : 876\n",
      "01101111 : 1640\n",
      "01110000 : 3386\n",
      "01110001 : 6792\n",
      "01110010 : 13611\n",
      "01110011 : 26837\n",
      "01110100 : 54149\n",
      "01110101 : 107389\n",
      "01110110 : 211426\n",
      "01110111 : 404887\n",
      "01111000 : 667300\n",
      "01111001 : 673833\n",
      "01111010 : 180440\n",
      "01111011 : 5735\n",
      "01111100 : 119\n",
      "01111101 : 4\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer4.1.conv2 layer's weight exponent bit count\n",
      "\n",
      "01100001 : 1\n",
      "01100011 : 1\n",
      "01100100 : 2\n",
      "01100101 : 2\n",
      "01100110 : 9\n",
      "01100111 : 6\n",
      "01101000 : 19\n",
      "01101001 : 37\n",
      "01101010 : 80\n",
      "01101011 : 165\n",
      "01101100 : 298\n",
      "01101101 : 639\n",
      "01101110 : 1238\n",
      "01101111 : 2314\n",
      "01110000 : 4783\n",
      "01110001 : 9450\n",
      "01110010 : 19265\n",
      "01110011 : 38004\n",
      "01110100 : 76279\n",
      "01110101 : 152306\n",
      "01110110 : 296472\n",
      "01110111 : 535666\n",
      "01111000 : 736790\n",
      "01111001 : 430839\n",
      "01111010 : 52096\n",
      "01111011 : 2392\n",
      "01111100 : 140\n",
      "01111101 : 3\n",
      "\n",
      "========================================\n",
      "total weight distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([120, 119, 117,  ..., 119, 119, 119], dtype=torch.int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_name = 'resnet18'\n",
    "\n",
    "if hasattr(models, net_name):\n",
    "    net = getattr(models, net_name)(pretrained=True)\n",
    "    print(f\"get pretrained net :  {net_name}\")\n",
    "else:\n",
    "    print(f\"model is not exist {net_name}\")\n",
    "\n",
    "total_weight_list = []\n",
    "for i, (n, m) in enumerate(net.named_modules()):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        weight_tensor = m.weight.data.flatten()\n",
    "        weight_exp = weight_tensor.view(torch.int32)\n",
    "        weight_exp = torch.div(weight_exp, (2**23), rounding_mode='floor')\n",
    "        weight_exp[weight_exp<0] += 256 # - value to plus\n",
    "        total_weight_list.append(weight_exp)\n",
    "        weight_exp_value, weight_exp_count = torch.unique(weight_exp, return_counts=True)\n",
    "        print(\"==\"*20)\n",
    "        print(f\"{n} layer's weight exponent bit count\")\n",
    "        print()\n",
    "        \n",
    "        for wv, wc in zip(weight_exp_value, weight_exp_count):\n",
    "            print(\"{:08b} : {}\".format(wv, wc))\n",
    "        \n",
    "        \n",
    "        print()\n",
    "        print(\"==\"*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec7721dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T01:46:23.398506Z",
     "start_time": "2022-08-26T01:46:22.863034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total weight distribution\n",
      "01010111 : 1\n",
      "01011001 : 2\n",
      "01011010 : 2\n",
      "01011011 : 9\n",
      "01011100 : 14\n",
      "01011101 : 27\n",
      "01011110 : 46\n",
      "01011111 : 123\n",
      "01100000 : 188\n",
      "01100001 : 388\n",
      "01100010 : 716\n",
      "01100011 : 1089\n",
      "01100100 : 807\n",
      "01100101 : 512\n",
      "01100110 : 448\n",
      "01100111 : 296\n",
      "01101000 : 339\n",
      "01101001 : 393\n",
      "01101010 : 578\n",
      "01101011 : 750\n",
      "01101100 : 1174\n",
      "01101101 : 2156\n",
      "01101110 : 4269\n",
      "01101111 : 8104\n",
      "01110000 : 16682\n",
      "01110001 : 33247\n",
      "01110010 : 66576\n",
      "01110011 : 133042\n",
      "01110100 : 267038\n",
      "01110101 : 532649\n",
      "01110110 : 1045515\n",
      "01110111 : 1965186\n",
      "01111000 : 3106924\n",
      "01111001 : 2904529\n",
      "01111010 : 942707\n",
      "01111011 : 116053\n",
      "01111100 : 12896\n",
      "01111101 : 1307\n",
      "01111110 : 127\n",
      "01111111 : 3\n"
     ]
    }
   ],
   "source": [
    "print(\"total weight distribution\")\n",
    "\n",
    "total_weight_tensor = torch.cat(total_weight_list)\n",
    "total_weight_value, total_weight_count = torch.unique(total_weight_tensor, return_counts=True)\n",
    "for wv, wc in zip(total_weight_value, total_weight_count):\n",
    "    print(\"{:08b} : {}\".format(wv, wc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fc3ef9",
   "metadata": {},
   "source": [
    "### resnet18 mask결과 front msb-4bit merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47718557",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T00:53:08.001895Z",
     "start_time": "2022-08-26T00:53:07.131540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get pretrained net :  resnet18\n",
      "========================================\n",
      "conv1 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  9408\n",
      "0101 : 31\n",
      "0110 : 1148\n",
      "0111 : 8229\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer1.0.conv1 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  36864\n",
      "0101 : 193\n",
      "0110 : 4446\n",
      "0111 : 32225\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer1.0.conv2 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  36864\n",
      "0110 : 35\n",
      "0111 : 36829\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer1.1.conv1 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  36864\n",
      "0110 : 30\n",
      "0111 : 36834\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer1.1.conv2 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  36864\n",
      "0110 : 26\n",
      "0111 : 36838\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.0.conv1 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  73728\n",
      "0110 : 71\n",
      "0111 : 73657\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.0.conv2 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  147456\n",
      "0110 : 140\n",
      "0111 : 147316\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.0.downsample.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  8192\n",
      "0110 : 5\n",
      "0111 : 8187\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.1.conv1 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  147456\n",
      "0110 : 125\n",
      "0111 : 147331\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.1.conv2 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  147456\n",
      "0110 : 156\n",
      "0111 : 147300\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.0.conv1 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  294912\n",
      "0110 : 301\n",
      "0111 : 294611\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.0.conv2 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  589824\n",
      "0110 : 634\n",
      "0111 : 589190\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.0.downsample.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  32768\n",
      "0110 : 30\n",
      "0111 : 32738\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.1.conv1 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  589824\n",
      "0110 : 768\n",
      "0111 : 589056\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.1.conv2 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  589824\n",
      "0110 : 810\n",
      "0111 : 589014\n",
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23822/4184500365.py:17: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  weight_mask_exp = weight_exp // (2**mask_value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "layer4.0.conv1 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  1179648\n",
      "0110 : 1646\n",
      "0111 : 1178002\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer4.0.conv2 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  2359296\n",
      "0110 : 3512\n",
      "0111 : 2355784\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer4.0.downsample.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  131072\n",
      "0110 : 125\n",
      "0111 : 130947\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer4.1.conv1 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  2359296\n",
      "0110 : 3388\n",
      "0111 : 2355908\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer4.1.conv2 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  2359296\n",
      "0110 : 4811\n",
      "0111 : 2354485\n",
      "\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "net_name = 'resnet18'\n",
    "\n",
    "if hasattr(models, net_name):\n",
    "    net = getattr(models, net_name)(pretrained=True)\n",
    "    print(f\"get pretrained net :  {net_name}\")\n",
    "else:\n",
    "    print(f\"model is not exist {net_name}\")\n",
    "\n",
    "mask_value = 4\n",
    "\n",
    "for i, (n, m) in enumerate(net.named_modules()):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        weight_tensor = m.weight.data.flatten()\n",
    "        weight_exp = weight_tensor.view(torch.int32)\n",
    "        weight_exp = torch.div(weight_exp, (2**23), rounding_mode='floor')\n",
    "        weight_exp[weight_exp<0] += 256 # minus value to plus (we only compute exponent value)\n",
    "        weight_mask_exp = weight_exp // (2**mask_value)\n",
    "        weight_exp_value, weight_exp_count = torch.unique(weight_mask_exp, return_counts=True)\n",
    "        print(\"==\"*20)\n",
    "        print(f\"{n} layer's weight exponent bit count (mask = {mask_value})\")\n",
    "        print()\n",
    "        print(\"total count: \", weight_tensor.numel())\n",
    "        value_count = 0\n",
    "        for wv, wc in zip(weight_exp_value, weight_exp_count):\n",
    "            print(\"{:04b} : {}\".format(wv, wc))\n",
    "            value_count += wc\n",
    "            \n",
    "        if not (weight_tensor.numel() - value_count) == 0:\n",
    "            print(\"# of number differ \", int(weight_tensor.numel()) - int(value_count))\n",
    "        print()\n",
    "        print(\"==\"*20)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96daa91f",
   "metadata": {},
   "source": [
    "### resnet18 mask결과 front msb-5bit merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f43381a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-25T06:56:45.469600Z",
     "start_time": "2022-08-25T06:56:44.572429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get pretrained net :  resnet18\n",
      "========================================\n",
      "conv1 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  9408\n",
      "01011 : 31\n",
      "01100 : 844\n",
      "01101 : 304\n",
      "01110 : 873\n",
      "01111 : 7356\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer1.0.conv1 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  36864\n",
      "01010 : 1\n",
      "01011 : 192\n",
      "01100 : 3525\n",
      "01101 : 921\n",
      "01110 : 6011\n",
      "01111 : 26214\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer1.0.conv2 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  36864\n",
      "01101 : 35\n",
      "01110 : 6989\n",
      "01111 : 29840\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer1.1.conv1 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  36864\n",
      "01101 : 30\n",
      "01110 : 6669\n",
      "01111 : 30165\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer1.1.conv2 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  36864\n",
      "01101 : 26\n",
      "01110 : 6950\n",
      "01111 : 29888\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.0.conv1 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  73728\n",
      "01100 : 1\n",
      "01101 : 70\n",
      "01110 : 15096\n",
      "01111 : 58561\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.0.conv2 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  147456\n",
      "01101 : 140\n",
      "01110 : 35335\n",
      "01111 : 111981\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.0.downsample.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  8192\n",
      "01101 : 5\n",
      "01110 : 1247\n",
      "01111 : 6940\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.1.conv1 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  147456\n",
      "01100 : 1\n",
      "01101 : 124\n",
      "01110 : 35038\n",
      "01111 : 112293\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.1.conv2 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  147456\n",
      "01100 : 2\n",
      "01101 : 154\n",
      "01110 : 36312\n",
      "01111 : 110988\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.0.conv1 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  294912\n",
      "01101 : 301\n",
      "01110 : 78720\n",
      "01111 : 215891\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.0.conv2 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  589824\n",
      "01100 : 2\n",
      "01101 : 632\n",
      "01110 : 173424\n",
      "01111 : 415766\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.0.downsample.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  32768\n",
      "01101 : 30\n",
      "01110 : 7846\n",
      "01111 : 24892\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.1.conv1 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  589824\n",
      "01100 : 5\n",
      "01101 : 763\n",
      "01110 : 186999\n",
      "01111 : 402057\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.1.conv2 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  589824\n",
      "01101 : 810\n",
      "01110 : 198982\n",
      "01111 : 390032\n",
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23822/2859858532.py:17: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  weight_mask_exp = weight_exp // (2**(8 - mask_value))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "layer4.0.conv1 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  1179648\n",
      "01100 : 6\n",
      "01101 : 1640\n",
      "01110 : 395220\n",
      "01111 : 782782\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer4.0.conv2 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  2359296\n",
      "01100 : 16\n",
      "01101 : 3496\n",
      "01110 : 876941\n",
      "01111 : 1478843\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer4.0.downsample.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  131072\n",
      "01100 : 1\n",
      "01101 : 124\n",
      "01110 : 30581\n",
      "01111 : 100366\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer4.1.conv1 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  2359296\n",
      "01100 : 20\n",
      "01101 : 3368\n",
      "01110 : 828477\n",
      "01111 : 1527431\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer4.1.conv2 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  2359296\n",
      "01100 : 21\n",
      "01101 : 4790\n",
      "01110 : 1132225\n",
      "01111 : 1222260\n",
      "\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "net_name = 'resnet18'\n",
    "\n",
    "if hasattr(models, net_name):\n",
    "    net = getattr(models, net_name)(pretrained=True)\n",
    "    print(f\"get pretrained net :  {net_name}\")\n",
    "else:\n",
    "    print(f\"model is not exist {net_name}\")\n",
    "\n",
    "mask_value = 5\n",
    "\n",
    "for i, (n, m) in enumerate(net.named_modules()):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        weight_tensor = m.weight.data.flatten()\n",
    "        weight_exp = weight_tensor.view(torch.int32)\n",
    "        weight_exp = torch.div(weight_exp, (2**23), rounding_mode='floor')\n",
    "        weight_exp[weight_exp<0] += 256 # minus value to plus (we only compute exponent value)\n",
    "        weight_mask_exp = weight_exp // (2**(8 - mask_value))\n",
    "        weight_exp_value, weight_exp_count = torch.unique(weight_mask_exp, return_counts=True)\n",
    "        print(\"==\"*20)\n",
    "        print(f\"{n} layer's weight exponent bit count (mask = {mask_value})\")\n",
    "        print()\n",
    "        print(\"total count: \", weight_tensor.numel())\n",
    "        value_count = 0\n",
    "        for wv, wc in zip(weight_exp_value, weight_exp_count):\n",
    "            print(\"{:05b} : {}\".format(wv, wc))\n",
    "            value_count += wc\n",
    "            \n",
    "        if not (weight_tensor.numel() - value_count) == 0:\n",
    "            print(\"# of number differ \", int(weight_tensor.numel()) - int(value_count))\n",
    "        print()\n",
    "        print(\"==\"*20)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea44607c",
   "metadata": {},
   "source": [
    "## mobilenet V2 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "041e607e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "features.0.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101111 : 1\n",
      "01110000 : 1\n",
      "01110001 : 6\n",
      "01110010 : 7\n",
      "01110011 : 21\n",
      "01110100 : 23\n",
      "01110101 : 49\n",
      "01110110 : 49\n",
      "01110111 : 40\n",
      "01111000 : 56\n",
      "01111001 : 94\n",
      "01111010 : 98\n",
      "01111011 : 135\n",
      "01111100 : 142\n",
      "01111101 : 94\n",
      "01111110 : 43\n",
      "01111111 : 5\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.1.conv.0.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01110010 : 1\n",
      "01110011 : 5\n",
      "01110100 : 6\n",
      "01110101 : 10\n",
      "01110110 : 15\n",
      "01110111 : 21\n",
      "01111000 : 23\n",
      "01111001 : 15\n",
      "01111010 : 34\n",
      "01111011 : 44\n",
      "01111100 : 36\n",
      "01111101 : 31\n",
      "01111110 : 33\n",
      "01111111 : 11\n",
      "10000000 : 3\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.1.conv.1 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01110001 : 1\n",
      "01110010 : 8\n",
      "01110011 : 7\n",
      "01110100 : 12\n",
      "01110101 : 19\n",
      "01110110 : 24\n",
      "01110111 : 26\n",
      "01111000 : 26\n",
      "01111001 : 27\n",
      "01111010 : 57\n",
      "01111011 : 89\n",
      "01111100 : 102\n",
      "01111101 : 93\n",
      "01111110 : 20\n",
      "01111111 : 1\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.2.conv.0.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101110 : 1\n",
      "01110010 : 1\n",
      "01110011 : 1\n",
      "01110100 : 10\n",
      "01110101 : 8\n",
      "01110110 : 18\n",
      "01110111 : 31\n",
      "01111000 : 59\n",
      "01111001 : 121\n",
      "01111010 : 221\n",
      "01111011 : 398\n",
      "01111100 : 441\n",
      "01111101 : 213\n",
      "01111110 : 13\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.2.conv.1.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01110001 : 1\n",
      "01110011 : 1\n",
      "01110100 : 1\n",
      "01110101 : 4\n",
      "01110110 : 2\n",
      "01110111 : 11\n",
      "01111000 : 25\n",
      "01111001 : 63\n",
      "01111010 : 126\n",
      "01111011 : 253\n",
      "01111100 : 284\n",
      "01111101 : 91\n",
      "01111110 : 2\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.2.conv.2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101101 : 1\n",
      "01110010 : 5\n",
      "01110011 : 3\n",
      "01110100 : 11\n",
      "01110101 : 12\n",
      "01110110 : 25\n",
      "01110111 : 55\n",
      "01111000 : 100\n",
      "01111001 : 182\n",
      "01111010 : 347\n",
      "01111011 : 623\n",
      "01111100 : 686\n",
      "01111101 : 236\n",
      "01111110 : 18\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.3.conv.0.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01110001 : 5\n",
      "01110010 : 2\n",
      "01110011 : 3\n",
      "01110100 : 12\n",
      "01110101 : 25\n",
      "01110110 : 48\n",
      "01110111 : 88\n",
      "01111000 : 188\n",
      "01111001 : 406\n",
      "01111010 : 723\n",
      "01111011 : 1029\n",
      "01111100 : 806\n",
      "01111101 : 120\n",
      "01111110 : 1\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.3.conv.1.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101111 : 1\n",
      "01110010 : 1\n",
      "01110011 : 3\n",
      "01110100 : 4\n",
      "01110101 : 9\n",
      "01110110 : 23\n",
      "01110111 : 33\n",
      "01111000 : 70\n",
      "01111001 : 150\n",
      "01111010 : 217\n",
      "01111011 : 287\n",
      "01111100 : 296\n",
      "01111101 : 178\n",
      "01111110 : 24\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.3.conv.2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01110001 : 3\n",
      "01110010 : 1\n",
      "01110011 : 2\n",
      "01110100 : 13\n",
      "01110101 : 27\n",
      "01110110 : 39\n",
      "01110111 : 86\n",
      "01111000 : 194\n",
      "01111001 : 397\n",
      "01111010 : 720\n",
      "01111011 : 1082\n",
      "01111100 : 764\n",
      "01111101 : 127\n",
      "01111110 : 1\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.4.conv.0.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01110000 : 1\n",
      "01110010 : 2\n",
      "01110011 : 11\n",
      "01110100 : 8\n",
      "01110101 : 24\n",
      "01110110 : 30\n",
      "01110111 : 69\n",
      "01111000 : 182\n",
      "01111001 : 321\n",
      "01111010 : 602\n",
      "01111011 : 916\n",
      "01111100 : 987\n",
      "01111101 : 290\n",
      "01111110 : 13\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.4.conv.1.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01110100 : 2\n",
      "01110101 : 2\n",
      "01110110 : 4\n",
      "01110111 : 7\n",
      "01111000 : 18\n",
      "01111001 : 48\n",
      "01111010 : 194\n",
      "01111011 : 587\n",
      "01111100 : 414\n",
      "01111101 : 20\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.4.conv.2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101111 : 1\n",
      "01110000 : 2\n",
      "01110001 : 4\n",
      "01110010 : 4\n",
      "01110011 : 5\n",
      "01110100 : 12\n",
      "01110101 : 30\n",
      "01110110 : 62\n",
      "01110111 : 109\n",
      "01111000 : 233\n",
      "01111001 : 446\n",
      "01111010 : 861\n",
      "01111011 : 1328\n",
      "01111100 : 1221\n",
      "01111101 : 287\n",
      "01111110 : 3\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.5.conv.0.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101111 : 1\n",
      "01110000 : 3\n",
      "01110001 : 1\n",
      "01110010 : 5\n",
      "01110011 : 20\n",
      "01110100 : 24\n",
      "01110101 : 51\n",
      "01110110 : 123\n",
      "01110111 : 218\n",
      "01111000 : 445\n",
      "01111001 : 880\n",
      "01111010 : 1582\n",
      "01111011 : 1910\n",
      "01111100 : 838\n",
      "01111101 : 42\n",
      "01111110 : 1\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.5.conv.1.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101100 : 1\n",
      "01101101 : 1\n",
      "01110010 : 2\n",
      "01110011 : 4\n",
      "01110100 : 7\n",
      "01110101 : 10\n",
      "01110110 : 23\n",
      "01110111 : 66\n",
      "01111000 : 109\n",
      "01111001 : 225\n",
      "01111010 : 412\n",
      "01111011 : 427\n",
      "01111100 : 274\n",
      "01111101 : 159\n",
      "01111110 : 8\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.5.conv.2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101111 : 1\n",
      "01110000 : 5\n",
      "01110001 : 5\n",
      "01110010 : 6\n",
      "01110011 : 11\n",
      "01110100 : 28\n",
      "01110101 : 48\n",
      "01110110 : 113\n",
      "01110111 : 251\n",
      "01111000 : 471\n",
      "01111001 : 913\n",
      "01111010 : 1523\n",
      "01111011 : 1924\n",
      "01111100 : 808\n",
      "01111101 : 37\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.6.conv.0.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101101 : 1\n",
      "01110000 : 3\n",
      "01110001 : 3\n",
      "01110010 : 6\n",
      "01110011 : 15\n",
      "01110100 : 33\n",
      "01110101 : 46\n",
      "01110110 : 120\n",
      "01110111 : 231\n",
      "01111000 : 532\n",
      "01111001 : 914\n",
      "01111010 : 1598\n",
      "01111011 : 1819\n",
      "01111100 : 791\n",
      "01111101 : 32\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.6.conv.1.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101111 : 3\n",
      "01110001 : 1\n",
      "01110010 : 3\n",
      "01110011 : 2\n",
      "01110100 : 7\n",
      "01110101 : 21\n",
      "01110110 : 30\n",
      "01110111 : 63\n",
      "01111000 : 133\n",
      "01111001 : 240\n",
      "01111010 : 363\n",
      "01111011 : 457\n",
      "01111100 : 312\n",
      "01111101 : 90\n",
      "01111110 : 3\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.6.conv.2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101101 : 1\n",
      "01110000 : 5\n",
      "01110001 : 5\n",
      "01110010 : 7\n",
      "01110011 : 23\n",
      "01110100 : 31\n",
      "01110101 : 58\n",
      "01110110 : 122\n",
      "01110111 : 238\n",
      "01111000 : 491\n",
      "01111001 : 889\n",
      "01111010 : 1632\n",
      "01111011 : 1961\n",
      "01111100 : 661\n",
      "01111101 : 20\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.7.conv.0.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101111 : 1\n",
      "01110000 : 2\n",
      "01110001 : 1\n",
      "01110010 : 6\n",
      "01110011 : 12\n",
      "01110100 : 25\n",
      "01110101 : 44\n",
      "01110110 : 80\n",
      "01110111 : 157\n",
      "01111000 : 301\n",
      "01111001 : 684\n",
      "01111010 : 1163\n",
      "01111011 : 1772\n",
      "01111100 : 1563\n",
      "01111101 : 331\n",
      "01111110 : 2\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.7.conv.1.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01110110 : 5\n",
      "01110111 : 5\n",
      "01111000 : 14\n",
      "01111001 : 59\n",
      "01111010 : 377\n",
      "01111011 : 790\n",
      "01111100 : 467\n",
      "01111101 : 11\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.7.conv.2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101101 : 1\n",
      "01101111 : 2\n",
      "01110000 : 3\n",
      "01110001 : 5\n",
      "01110010 : 18\n",
      "01110011 : 23\n",
      "01110100 : 43\n",
      "01110101 : 94\n",
      "01110110 : 187\n",
      "01110111 : 397\n",
      "01111000 : 799\n",
      "01111001 : 1469\n",
      "01111010 : 2768\n",
      "01111011 : 3913\n",
      "01111100 : 2329\n",
      "01111101 : 237\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.8.conv.0.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101000 : 1\n",
      "01101010 : 1\n",
      "01101100 : 1\n",
      "01101101 : 1\n",
      "01101110 : 2\n",
      "01101111 : 1\n",
      "01110000 : 14\n",
      "01110001 : 16\n",
      "01110010 : 49\n",
      "01110011 : 88\n",
      "01110100 : 162\n",
      "01110101 : 321\n",
      "01110110 : 731\n",
      "01110111 : 1384\n",
      "01111000 : 2701\n",
      "01111001 : 5104\n",
      "01111010 : 7610\n",
      "01111011 : 5598\n",
      "01111100 : 784\n",
      "01111101 : 7\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.8.conv.1.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101111 : 1\n",
      "01110000 : 1\n",
      "01110001 : 1\n",
      "01110010 : 4\n",
      "01110011 : 6\n",
      "01110100 : 18\n",
      "01110101 : 36\n",
      "01110110 : 74\n",
      "01110111 : 152\n",
      "01111000 : 258\n",
      "01111001 : 522\n",
      "01111010 : 1015\n",
      "01111011 : 788\n",
      "01111100 : 403\n",
      "01111101 : 176\n",
      "01111110 : 1\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.8.conv.2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101001 : 2\n",
      "01101100 : 1\n",
      "01101110 : 3\n",
      "01101111 : 5\n",
      "01110000 : 7\n",
      "01110001 : 20\n",
      "01110010 : 49\n",
      "01110011 : 86\n",
      "01110100 : 159\n",
      "01110101 : 323\n",
      "01110110 : 689\n",
      "01110111 : 1434\n",
      "01111000 : 2718\n",
      "01111001 : 4892\n",
      "01111010 : 7652\n",
      "01111011 : 5768\n",
      "01111100 : 766\n",
      "01111101 : 2\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.9.conv.0.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101011 : 1\n",
      "01101100 : 1\n",
      "01101101 : 2\n",
      "01101110 : 2\n",
      "01101111 : 8\n",
      "01110000 : 12\n",
      "01110001 : 24\n",
      "01110010 : 49\n",
      "01110011 : 92\n",
      "01110100 : 173\n",
      "01110101 : 372\n",
      "01110110 : 733\n",
      "01110111 : 1433\n",
      "01111000 : 2740\n",
      "01111001 : 5014\n",
      "01111010 : 7448\n",
      "01111011 : 5717\n",
      "01111100 : 751\n",
      "01111101 : 4\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.9.conv.1.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01110000 : 3\n",
      "01110001 : 2\n",
      "01110010 : 4\n",
      "01110011 : 12\n",
      "01110100 : 18\n",
      "01110101 : 41\n",
      "01110110 : 74\n",
      "01110111 : 164\n",
      "01111000 : 315\n",
      "01111001 : 568\n",
      "01111010 : 1012\n",
      "01111011 : 754\n",
      "01111100 : 417\n",
      "01111101 : 71\n",
      "01111110 : 1\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.9.conv.2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101100 : 1\n",
      "01101110 : 3\n",
      "01101111 : 8\n",
      "01110000 : 11\n",
      "01110001 : 22\n",
      "01110010 : 47\n",
      "01110011 : 92\n",
      "01110100 : 207\n",
      "01110101 : 338\n",
      "01110110 : 775\n",
      "01110111 : 1600\n",
      "01111000 : 2837\n",
      "01111001 : 5144\n",
      "01111010 : 7705\n",
      "01111011 : 5289\n",
      "01111100 : 495\n",
      "01111101 : 2\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.10.conv.0.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101110 : 3\n",
      "01101111 : 3\n",
      "01110000 : 10\n",
      "01110001 : 24\n",
      "01110010 : 35\n",
      "01110011 : 91\n",
      "01110100 : 181\n",
      "01110101 : 351\n",
      "01110110 : 655\n",
      "01110111 : 1431\n",
      "01111000 : 2724\n",
      "01111001 : 4912\n",
      "01111010 : 7517\n",
      "01111011 : 5848\n",
      "01111100 : 789\n",
      "01111101 : 2\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.10.conv.1.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101111 : 1\n",
      "01110000 : 2\n",
      "01110001 : 5\n",
      "01110010 : 5\n",
      "01110011 : 8\n",
      "01110100 : 22\n",
      "01110101 : 43\n",
      "01110110 : 75\n",
      "01110111 : 177\n",
      "01111000 : 305\n",
      "01111001 : 615\n",
      "01111010 : 1012\n",
      "01111011 : 758\n",
      "01111100 : 406\n",
      "01111101 : 21\n",
      "01111110 : 1\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.10.conv.2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101010 : 2\n",
      "01101011 : 1\n",
      "01101100 : 2\n",
      "01101110 : 5\n",
      "01101111 : 7\n",
      "01110000 : 10\n",
      "01110001 : 28\n",
      "01110010 : 52\n",
      "01110011 : 93\n",
      "01110100 : 209\n",
      "01110101 : 358\n",
      "01110110 : 716\n",
      "01110111 : 1564\n",
      "01111000 : 2830\n",
      "01111001 : 5178\n",
      "01111010 : 7582\n",
      "01111011 : 5372\n",
      "01111100 : 558\n",
      "01111101 : 9\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.11.conv.0.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101101 : 2\n",
      "01101111 : 2\n",
      "01110000 : 5\n",
      "01110001 : 15\n",
      "01110010 : 26\n",
      "01110011 : 58\n",
      "01110100 : 121\n",
      "01110101 : 231\n",
      "01110110 : 526\n",
      "01110111 : 939\n",
      "01111000 : 1968\n",
      "01111001 : 3742\n",
      "01111010 : 6403\n",
      "01111011 : 7507\n",
      "01111100 : 2915\n",
      "01111101 : 116\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.11.conv.1.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101010 : 1\n",
      "01110000 : 2\n",
      "01110001 : 1\n",
      "01110010 : 5\n",
      "01110011 : 15\n",
      "01110100 : 25\n",
      "01110101 : 38\n",
      "01110110 : 99\n",
      "01110111 : 195\n",
      "01111000 : 380\n",
      "01111001 : 611\n",
      "01111010 : 889\n",
      "01111011 : 697\n",
      "01111100 : 270\n",
      "01111101 : 223\n",
      "01111110 : 5\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.11.conv.2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101010 : 1\n",
      "01101100 : 2\n",
      "01101110 : 4\n",
      "01101111 : 8\n",
      "01110000 : 13\n",
      "01110001 : 26\n",
      "01110010 : 61\n",
      "01110011 : 104\n",
      "01110100 : 236\n",
      "01110101 : 439\n",
      "01110110 : 866\n",
      "01110111 : 1620\n",
      "01111000 : 3256\n",
      "01111001 : 6306\n",
      "01111010 : 10379\n",
      "01111011 : 10582\n",
      "01111100 : 2906\n",
      "01111101 : 55\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.12.conv.0.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101011 : 1\n",
      "01101100 : 3\n",
      "01101101 : 3\n",
      "01101110 : 8\n",
      "01101111 : 15\n",
      "01110000 : 35\n",
      "01110001 : 58\n",
      "01110010 : 117\n",
      "01110011 : 231\n",
      "01110100 : 407\n",
      "01110101 : 855\n",
      "01110110 : 1752\n",
      "01110111 : 3416\n",
      "01111000 : 6615\n",
      "01111001 : 11572\n",
      "01111010 : 17006\n",
      "01111011 : 11902\n",
      "01111100 : 1295\n",
      "01111101 : 5\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.12.conv.1.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101111 : 1\n",
      "01110000 : 1\n",
      "01110001 : 2\n",
      "01110010 : 9\n",
      "01110011 : 10\n",
      "01110100 : 14\n",
      "01110101 : 47\n",
      "01110110 : 87\n",
      "01110111 : 238\n",
      "01111000 : 403\n",
      "01111001 : 879\n",
      "01111010 : 1874\n",
      "01111011 : 1065\n",
      "01111100 : 483\n",
      "01111101 : 70\n",
      "01111110 : 1\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.12.conv.2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101010 : 2\n",
      "01101100 : 2\n",
      "01101101 : 2\n",
      "01101110 : 9\n",
      "01101111 : 16\n",
      "01110000 : 28\n",
      "01110001 : 69\n",
      "01110010 : 135\n",
      "01110011 : 205\n",
      "01110100 : 464\n",
      "01110101 : 904\n",
      "01110110 : 1809\n",
      "01110111 : 3551\n",
      "01111000 : 6500\n",
      "01111001 : 11736\n",
      "01111010 : 17177\n",
      "01111011 : 11621\n",
      "01111100 : 1063\n",
      "01111101 : 3\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.13.conv.0.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100111 : 1\n",
      "01101000 : 1\n",
      "01101011 : 1\n",
      "01101101 : 2\n",
      "01101110 : 8\n",
      "01101111 : 12\n",
      "01110000 : 30\n",
      "01110001 : 60\n",
      "01110010 : 108\n",
      "01110011 : 235\n",
      "01110100 : 438\n",
      "01110101 : 865\n",
      "01110110 : 1680\n",
      "01110111 : 3356\n",
      "01111000 : 6244\n",
      "01111001 : 11532\n",
      "01111010 : 17073\n",
      "01111011 : 12214\n",
      "01111100 : 1431\n",
      "01111101 : 5\n",
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "features.13.conv.1.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101111 : 2\n",
      "01110000 : 2\n",
      "01110001 : 1\n",
      "01110010 : 6\n",
      "01110011 : 15\n",
      "01110100 : 28\n",
      "01110101 : 49\n",
      "01110110 : 91\n",
      "01110111 : 180\n",
      "01111000 : 403\n",
      "01111001 : 926\n",
      "01111010 : 1977\n",
      "01111011 : 1019\n",
      "01111100 : 447\n",
      "01111101 : 37\n",
      "01111110 : 1\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.13.conv.2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101001 : 1\n",
      "01101100 : 1\n",
      "01101101 : 4\n",
      "01101110 : 12\n",
      "01101111 : 9\n",
      "01110000 : 38\n",
      "01110001 : 63\n",
      "01110010 : 125\n",
      "01110011 : 232\n",
      "01110100 : 500\n",
      "01110101 : 966\n",
      "01110110 : 1886\n",
      "01110111 : 3428\n",
      "01111000 : 6583\n",
      "01111001 : 12110\n",
      "01111010 : 17297\n",
      "01111011 : 11071\n",
      "01111100 : 954\n",
      "01111101 : 15\n",
      "01111110 : 1\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.14.conv.0.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100110 : 1\n",
      "01100111 : 1\n",
      "01101011 : 1\n",
      "01101100 : 1\n",
      "01101101 : 1\n",
      "01101110 : 3\n",
      "01101111 : 13\n",
      "01110000 : 25\n",
      "01110001 : 40\n",
      "01110010 : 67\n",
      "01110011 : 160\n",
      "01110100 : 339\n",
      "01110101 : 642\n",
      "01110110 : 1283\n",
      "01110111 : 2504\n",
      "01111000 : 5018\n",
      "01111001 : 9507\n",
      "01111010 : 15629\n",
      "01111011 : 15836\n",
      "01111100 : 4140\n",
      "01111101 : 85\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.14.conv.1.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101111 : 1\n",
      "01110000 : 2\n",
      "01110100 : 1\n",
      "01110101 : 1\n",
      "01110110 : 8\n",
      "01110111 : 14\n",
      "01111000 : 38\n",
      "01111001 : 304\n",
      "01111010 : 2049\n",
      "01111011 : 2409\n",
      "01111100 : 356\n",
      "01111101 : 1\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.14.conv.2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101010 : 1\n",
      "01101011 : 1\n",
      "01101100 : 2\n",
      "01101101 : 6\n",
      "01101110 : 6\n",
      "01101111 : 20\n",
      "01110000 : 27\n",
      "01110001 : 96\n",
      "01110010 : 135\n",
      "01110011 : 300\n",
      "01110100 : 645\n",
      "01110101 : 1138\n",
      "01110110 : 2390\n",
      "01110111 : 4638\n",
      "01111000 : 9197\n",
      "01111001 : 17028\n",
      "01111010 : 27458\n",
      "01111011 : 24503\n",
      "01111100 : 4538\n",
      "01111101 : 31\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.15.conv.0.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101000 : 1\n",
      "01101011 : 4\n",
      "01101101 : 10\n",
      "01101110 : 16\n",
      "01101111 : 54\n",
      "01110000 : 94\n",
      "01110001 : 163\n",
      "01110010 : 353\n",
      "01110011 : 718\n",
      "01110100 : 1353\n",
      "01110101 : 2838\n",
      "01110110 : 5509\n",
      "01110111 : 10868\n",
      "01111000 : 21328\n",
      "01111001 : 37648\n",
      "01111010 : 48453\n",
      "01111011 : 23132\n",
      "01111100 : 1057\n",
      "01111101 : 1\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.15.conv.1.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101100 : 1\n",
      "01101110 : 1\n",
      "01110000 : 1\n",
      "01110001 : 3\n",
      "01110010 : 10\n",
      "01110011 : 9\n",
      "01110100 : 19\n",
      "01110101 : 50\n",
      "01110110 : 91\n",
      "01110111 : 224\n",
      "01111000 : 450\n",
      "01111001 : 1053\n",
      "01111010 : 3446\n",
      "01111011 : 2353\n",
      "01111100 : 877\n",
      "01111101 : 51\n",
      "01111110 : 1\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.15.conv.2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101010 : 2\n",
      "01101011 : 3\n",
      "01101100 : 2\n",
      "01101101 : 11\n",
      "01101110 : 30\n",
      "01101111 : 37\n",
      "01110000 : 80\n",
      "01110001 : 173\n",
      "01110010 : 347\n",
      "01110011 : 712\n",
      "01110100 : 1372\n",
      "01110101 : 2725\n",
      "01110110 : 5318\n",
      "01110111 : 10707\n",
      "01111000 : 21028\n",
      "01111001 : 37315\n",
      "01111010 : 48893\n",
      "01111011 : 23712\n",
      "01111100 : 1133\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.16.conv.0.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101011 : 3\n",
      "01101100 : 4\n",
      "01101101 : 7\n",
      "01101110 : 17\n",
      "01101111 : 25\n",
      "01110000 : 73\n",
      "01110001 : 172\n",
      "01110010 : 330\n",
      "01110011 : 662\n",
      "01110100 : 1299\n",
      "01110101 : 2476\n",
      "01110110 : 5136\n",
      "01110111 : 9942\n",
      "01111000 : 19318\n",
      "01111001 : 34987\n",
      "01111010 : 48388\n",
      "01111011 : 28643\n",
      "01111100 : 2118\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.16.conv.1.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101111 : 3\n",
      "01110000 : 2\n",
      "01110001 : 4\n",
      "01110010 : 10\n",
      "01110011 : 23\n",
      "01110100 : 31\n",
      "01110101 : 65\n",
      "01110110 : 132\n",
      "01110111 : 279\n",
      "01111000 : 505\n",
      "01111001 : 1349\n",
      "01111010 : 3707\n",
      "01111011 : 1911\n",
      "01111100 : 568\n",
      "01111101 : 51\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.16.conv.2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100111 : 1\n",
      "01101001 : 1\n",
      "01101011 : 1\n",
      "01101100 : 5\n",
      "01101101 : 9\n",
      "01101110 : 21\n",
      "01101111 : 37\n",
      "01110000 : 107\n",
      "01110001 : 160\n",
      "01110010 : 371\n",
      "01110011 : 695\n",
      "01110100 : 1394\n",
      "01110101 : 2764\n",
      "01110110 : 5335\n",
      "01110111 : 10554\n",
      "01111000 : 20126\n",
      "01111001 : 36352\n",
      "01111010 : 48859\n",
      "01111011 : 25384\n",
      "01111100 : 1420\n",
      "01111101 : 4\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.17.conv.0.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100110 : 1\n",
      "01101010 : 1\n",
      "01101100 : 4\n",
      "01101101 : 7\n",
      "01101110 : 23\n",
      "01101111 : 38\n",
      "01110000 : 72\n",
      "01110001 : 152\n",
      "01110010 : 291\n",
      "01110011 : 565\n",
      "01110100 : 1091\n",
      "01110101 : 2141\n",
      "01110110 : 4272\n",
      "01110111 : 8408\n",
      "01111000 : 16823\n",
      "01111001 : 30921\n",
      "01111010 : 47206\n",
      "01111011 : 37097\n",
      "01111100 : 4484\n",
      "01111101 : 3\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.17.conv.1.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01110001 : 1\n",
      "01110101 : 3\n",
      "01110110 : 15\n",
      "01110111 : 107\n",
      "01111000 : 1500\n",
      "01111001 : 5821\n",
      "01111010 : 1138\n",
      "01111011 : 44\n",
      "01111100 : 11\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.17.conv.2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100101 : 1\n",
      "01100110 : 1\n",
      "01101001 : 2\n",
      "01101010 : 2\n",
      "01101011 : 4\n",
      "01101100 : 10\n",
      "01101101 : 28\n",
      "01101110 : 35\n",
      "01101111 : 82\n",
      "01110000 : 170\n",
      "01110001 : 362\n",
      "01110010 : 738\n",
      "01110011 : 1488\n",
      "01110100 : 2894\n",
      "01110101 : 5861\n",
      "01110110 : 11771\n",
      "01110111 : 22848\n",
      "01111000 : 43803\n",
      "01111001 : 77735\n",
      "01111010 : 97584\n",
      "01111011 : 40856\n",
      "01111100 : 925\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.18.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100111 : 1\n",
      "01101001 : 1\n",
      "01101010 : 6\n",
      "01101011 : 12\n",
      "01101100 : 23\n",
      "01101101 : 35\n",
      "01101110 : 69\n",
      "01101111 : 189\n",
      "01110000 : 341\n",
      "01110001 : 652\n",
      "01110010 : 1347\n",
      "01110011 : 2663\n",
      "01110100 : 5238\n",
      "01110101 : 10451\n",
      "01110110 : 20979\n",
      "01110111 : 41011\n",
      "01111000 : 77348\n",
      "01111001 : 123352\n",
      "01111010 : 109074\n",
      "01111011 : 16776\n",
      "01111100 : 32\n",
      "\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "net_name = 'mobilenet_v2'\n",
    "\n",
    "if hasattr(models, net_name):\n",
    "    net = getattr(models, net_name)(pretrained=True)\n",
    "    print(f\"get pretrained net :  {net_name}\")\n",
    "else:\n",
    "    print(f\"model is not exist {net_name}\")\n",
    "\n",
    "for i, (n, m) in enumerate(net.named_modules()):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        weight_tensor = m.weight.data.flatten()\n",
    "        weight_exp = weight_tensor.view(torch.int32)\n",
    "        weight_exp = torch.div(weight_exp, (2**23), rounding_mode='floor')\n",
    "        weight_exp[weight_exp<0] += 256 # - value to plus\n",
    "        weight_exp_value, weight_exp_count = torch.unique(weight_exp, return_counts=True)\n",
    "        weight_zero_count = (weight_tensor == 0).sum()\n",
    "        print(\"==\"*20)\n",
    "        print(f\"{n} layer's weight exponent bit count\")\n",
    "        print(f\"zero count : {weight_zero_count}\")\n",
    "        print()\n",
    "        for wv, wc in zip(weight_exp_value, weight_exp_count):\n",
    "            print(\"{:08b} : {}\".format(wv, wc))\n",
    "        print()\n",
    "        print(\"==\"*20)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69caed06",
   "metadata": {},
   "source": [
    "### mobilenet mask 결과 (4bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a7ccd51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T00:50:46.259508Z",
     "start_time": "2022-08-26T00:50:45.989795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get pretrained net :  mobilenet_v2\n",
      "========================================\n",
      "features.0.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  864\n",
      "0110 : 1\n",
      "0111 : 863\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.1.conv.0.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  288\n",
      "0111 : 285\n",
      "1000 : 3\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.1.conv.1 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  512\n",
      "0111 : 512\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.2.conv.0.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  1536\n",
      "0110 : 1\n",
      "0111 : 1535\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.2.conv.1.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  864\n",
      "0111 : 864\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.2.conv.2 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  2304\n",
      "0110 : 1\n",
      "0111 : 2303\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.3.conv.0.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  3456\n",
      "0111 : 3456\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.3.conv.1.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  1296\n",
      "0110 : 1\n",
      "0111 : 1295\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.3.conv.2 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  3456\n",
      "0111 : 3456\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.4.conv.0.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  3456\n",
      "0111 : 3456\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.4.conv.1.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  1296\n",
      "0111 : 1296\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.4.conv.2 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  4608\n",
      "0110 : 1\n",
      "0111 : 4607\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.5.conv.0.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  6144\n",
      "0110 : 1\n",
      "0111 : 6143\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.5.conv.1.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  1728\n",
      "0110 : 2\n",
      "0111 : 1726\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.5.conv.2 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  6144\n",
      "0110 : 1\n",
      "0111 : 6143\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.6.conv.0.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  6144\n",
      "0110 : 1\n",
      "0111 : 6143\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.6.conv.1.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  1728\n",
      "0110 : 3\n",
      "0111 : 1725\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.6.conv.2 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  6144\n",
      "0110 : 1\n",
      "0111 : 6143\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.7.conv.0.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  6144\n",
      "0110 : 1\n",
      "0111 : 6143\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.7.conv.1.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  1728\n",
      "0111 : 1728\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.7.conv.2 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  12288\n",
      "0110 : 3\n",
      "0111 : 12285\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.8.conv.0.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  24576\n",
      "0110 : 7\n",
      "0111 : 24569\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.8.conv.1.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  3456\n",
      "0110 : 1\n",
      "0111 : 3455\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.8.conv.2 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  24576\n",
      "0110 : 11\n",
      "0111 : 24565\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.9.conv.0.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  24576\n",
      "0110 : 14\n",
      "0111 : 24562\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.9.conv.1.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  3456\n",
      "0111 : 3456\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.9.conv.2 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  24576\n",
      "0110 : 12\n",
      "0111 : 24564\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.10.conv.0.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  24576\n",
      "0110 : 6\n",
      "0111 : 24570\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.10.conv.1.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  3456\n",
      "0110 : 1\n",
      "0111 : 3455\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.10.conv.2 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  24576\n",
      "0110 : 17\n",
      "0111 : 24559\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.11.conv.0.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  24576\n",
      "0110 : 4\n",
      "0111 : 24572\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.11.conv.1.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  3456\n",
      "0110 : 1\n",
      "0111 : 3455\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.11.conv.2 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  36864\n",
      "0110 : 15\n",
      "0111 : 36849\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.12.conv.0.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  55296\n",
      "0110 : 30\n",
      "0111 : 55266\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.12.conv.1.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  5184\n",
      "0110 : 1\n",
      "0111 : 5183\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.12.conv.2 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  55296\n",
      "0110 : 31\n",
      "0111 : 55265\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.13.conv.0.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  55296\n",
      "0110 : 25\n",
      "0111 : 55271\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.13.conv.1.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  5184\n",
      "0110 : 2\n",
      "0111 : 5182\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.13.conv.2 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  55296\n",
      "0110 : 27\n",
      "0111 : 55269\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.14.conv.0.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  55296\n",
      "0110 : 21\n",
      "0111 : 55275\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.14.conv.1.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  5184\n",
      "0110 : 1\n",
      "0111 : 5183\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.14.conv.2 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  92160\n",
      "0110 : 36\n",
      "0111 : 92124\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.15.conv.0.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  153600\n",
      "0110 : 85\n",
      "0111 : 153515\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.15.conv.1.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  8640\n",
      "0110 : 2\n",
      "0111 : 8638\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.15.conv.2 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  153600\n",
      "0110 : 85\n",
      "0111 : 153515\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.16.conv.0.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  153600\n",
      "0110 : 56\n",
      "0111 : 153544\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.16.conv.1.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  8640\n",
      "0110 : 3\n",
      "0111 : 8637\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.16.conv.2 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  153600\n",
      "0110 : 75\n",
      "0111 : 153525\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.17.conv.0.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  153600\n",
      "0110 : 74\n",
      "0111 : 153526\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.17.conv.1.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  8640\n",
      "0111 : 8640\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.17.conv.2 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  307200\n",
      "0110 : 165\n",
      "0111 : 307035\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.18.0 layer's weight exponent bit count (mask = 4)\n",
      "\n",
      "total count:  409600\n",
      "0110 : 336\n",
      "0111 : 409264\n",
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23822/2544817611.py:17: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  weight_mask_exp = weight_exp // (2**(8 - mask_value))\n"
     ]
    }
   ],
   "source": [
    "net_name = 'mobilenet_v2'\n",
    "\n",
    "if hasattr(models, net_name):\n",
    "    net = getattr(models, net_name)(pretrained=True)\n",
    "    print(f\"get pretrained net :  {net_name}\")\n",
    "else:\n",
    "    print(f\"model is not exist {net_name}\")\n",
    "\n",
    "mask_value = 4\n",
    "\n",
    "for i, (n, m) in enumerate(net.named_modules()):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        weight_tensor = m.weight.data.flatten()\n",
    "        weight_exp = weight_tensor.view(torch.int32)\n",
    "        weight_exp = torch.div(weight_exp, (2**23), rounding_mode='floor')\n",
    "        weight_exp[weight_exp<0] += 256 # minus value to plus (we only compute exponent value)\n",
    "        weight_mask_exp = weight_exp // (2**(8 - mask_value))\n",
    "        weight_exp_value, weight_exp_count = torch.unique(weight_mask_exp, return_counts=True)\n",
    "        print(\"==\"*20)\n",
    "        print(f\"{n} layer's weight exponent bit count (mask = {mask_value})\")\n",
    "        print()\n",
    "        print(\"total count: \", weight_tensor.numel())\n",
    "        value_count = 0\n",
    "        for wv, wc in zip(weight_exp_value, weight_exp_count):\n",
    "            print(\"{:04b} : {}\".format(wv, wc))\n",
    "            value_count += wc\n",
    "            \n",
    "        if not (weight_tensor.numel() - value_count) == 0:\n",
    "            print(\"# of number differ \", int(weight_tensor.numel()) - int(value_count))\n",
    "        print()\n",
    "        print(\"==\"*20)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfd5de4",
   "metadata": {},
   "source": [
    "### 5bit 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e21a77a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T00:48:58.142125Z",
     "start_time": "2022-08-26T00:48:57.808731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get pretrained net :  mobilenet_v2\n",
      "========================================\n",
      "features.0.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  864\n",
      "01101 : 1\n",
      "01110 : 196\n",
      "01111 : 667\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.1.conv.0.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  288\n",
      "01110 : 58\n",
      "01111 : 227\n",
      "10000 : 3\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.1.conv.1 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  512\n",
      "01110 : 97\n",
      "01111 : 415\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.2.conv.0.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  1536\n",
      "01101 : 1\n",
      "01110 : 69\n",
      "01111 : 1466\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.2.conv.1.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  864\n",
      "01110 : 20\n",
      "01111 : 844\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.2.conv.2 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  2304\n",
      "01101 : 1\n",
      "01110 : 111\n",
      "01111 : 2192\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.3.conv.0.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  3456\n",
      "01110 : 183\n",
      "01111 : 3273\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.3.conv.1.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  1296\n",
      "01101 : 1\n",
      "01110 : 73\n",
      "01111 : 1222\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.3.conv.2 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  3456\n",
      "01110 : 171\n",
      "01111 : 3285\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.4.conv.0.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  3456\n",
      "01110 : 145\n",
      "01111 : 3311\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.4.conv.1.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  1296\n",
      "01110 : 15\n",
      "01111 : 1281\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.4.conv.2 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  4608\n",
      "01101 : 1\n",
      "01110 : 228\n",
      "01111 : 4379\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.5.conv.0.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  6144\n",
      "01101 : 1\n",
      "01110 : 445\n",
      "01111 : 5698\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.5.conv.1.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  1728\n",
      "01101 : 2\n",
      "01110 : 112\n",
      "01111 : 1614\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.5.conv.2 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  6144\n",
      "01101 : 1\n",
      "01110 : 467\n",
      "01111 : 5676\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.6.conv.0.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  6144\n",
      "01101 : 1\n",
      "01110 : 457\n",
      "01111 : 5686\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.6.conv.1.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  1728\n",
      "01101 : 3\n",
      "01110 : 127\n",
      "01111 : 1598\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.6.conv.2 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  6144\n",
      "01101 : 1\n",
      "01110 : 489\n",
      "01111 : 5654\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.7.conv.0.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  6144\n",
      "01101 : 1\n",
      "01110 : 327\n",
      "01111 : 5816\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.7.conv.1.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  1728\n",
      "01110 : 10\n",
      "01111 : 1718\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.7.conv.2 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  12288\n",
      "01101 : 3\n",
      "01110 : 770\n",
      "01111 : 11515\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.8.conv.0.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  24576\n",
      "01101 : 7\n",
      "01110 : 2765\n",
      "01111 : 21804\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.8.conv.1.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  3456\n",
      "01101 : 1\n",
      "01110 : 292\n",
      "01111 : 3163\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.8.conv.2 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  24576\n",
      "01101 : 11\n",
      "01110 : 2767\n",
      "01111 : 21798\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.9.conv.0.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  24576\n",
      "01101 : 14\n",
      "01110 : 2888\n",
      "01111 : 21674\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.9.conv.1.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  3456\n",
      "01110 : 318\n",
      "01111 : 3138\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.9.conv.2 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  24576\n",
      "01101 : 12\n",
      "01110 : 3092\n",
      "01111 : 21472\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.10.conv.0.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  24576\n",
      "01101 : 6\n",
      "01110 : 2778\n",
      "01111 : 21792\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.10.conv.1.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  3456\n",
      "01101 : 1\n",
      "01110 : 337\n",
      "01111 : 3118\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.10.conv.2 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  24576\n",
      "01101 : 17\n",
      "01110 : 3030\n",
      "01111 : 21529\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.11.conv.0.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  24576\n",
      "01101 : 4\n",
      "01110 : 1921\n",
      "01111 : 22651\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.11.conv.1.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  3456\n",
      "01101 : 1\n",
      "01110 : 380\n",
      "01111 : 3075\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.11.conv.2 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  36864\n",
      "01101 : 15\n",
      "01110 : 3365\n",
      "01111 : 33484\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.12.conv.0.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  55296\n",
      "01101 : 30\n",
      "01110 : 6871\n",
      "01111 : 48395\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.12.conv.1.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  5184\n",
      "01101 : 1\n",
      "01110 : 408\n",
      "01111 : 4775\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.12.conv.2 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  55296\n",
      "01101 : 31\n",
      "01110 : 7165\n",
      "01111 : 48100\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.13.conv.0.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  55296\n",
      "01100 : 1\n",
      "01101 : 24\n",
      "01110 : 6772\n",
      "01111 : 48499\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.13.conv.1.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  5184\n",
      "01101 : 2\n",
      "01110 : 372\n",
      "01111 : 4810\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.13.conv.2 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  55296\n",
      "01101 : 27\n",
      "01110 : 7238\n",
      "01111 : 48031\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.14.conv.0.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  55296\n",
      "01100 : 2\n",
      "01101 : 19\n",
      "01110 : 5060\n",
      "01111 : 50215\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.14.conv.1.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  5184\n",
      "01101 : 1\n",
      "01110 : 26\n",
      "01111 : 5157\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.14.conv.2 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  92160\n",
      "01101 : 36\n",
      "01110 : 9369\n",
      "01111 : 82755\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.15.conv.0.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  153600\n",
      "01101 : 85\n",
      "01110 : 21896\n",
      "01111 : 131619\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.15.conv.1.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  8640\n",
      "01101 : 2\n",
      "01110 : 407\n",
      "01111 : 8231\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.15.conv.2 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  153600\n",
      "01101 : 85\n",
      "01110 : 21434\n",
      "01111 : 132081\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.16.conv.0.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  153600\n",
      "01101 : 56\n",
      "01110 : 20090\n",
      "01111 : 133454\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.16.conv.1.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  8640\n",
      "01101 : 3\n",
      "01110 : 546\n",
      "01111 : 8091\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.16.conv.2 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  153600\n",
      "01100 : 1\n",
      "01101 : 74\n",
      "01110 : 21380\n",
      "01111 : 132145\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.17.conv.0.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  153600\n",
      "01100 : 1\n",
      "01101 : 73\n",
      "01110 : 16992\n",
      "01111 : 136534\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.17.conv.1.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  8640\n",
      "01110 : 126\n",
      "01111 : 8514\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "features.17.conv.2 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  307200\n",
      "01100 : 2\n",
      "01101 : 163\n",
      "01110 : 46132\n",
      "01111 : 260903\n",
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23822/331088876.py:17: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  weight_mask_exp = weight_exp // (2**(8 - mask_value))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "features.18.0 layer's weight exponent bit count (mask = 5)\n",
      "\n",
      "total count:  409600\n",
      "01100 : 1\n",
      "01101 : 335\n",
      "01110 : 82682\n",
      "01111 : 326582\n",
      "\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "net_name = 'mobilenet_v2'\n",
    "\n",
    "if hasattr(models, net_name):\n",
    "    net = getattr(models, net_name)(pretrained=True)\n",
    "    print(f\"get pretrained net :  {net_name}\")\n",
    "else:\n",
    "    print(f\"model is not exist {net_name}\")\n",
    "\n",
    "mask_value = 5\n",
    "\n",
    "for i, (n, m) in enumerate(net.named_modules()):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        weight_tensor = m.weight.data.flatten()\n",
    "        weight_exp = weight_tensor.view(torch.int32)\n",
    "        weight_exp = torch.div(weight_exp, (2**23), rounding_mode='floor')\n",
    "        weight_exp[weight_exp<0] += 256 # minus value to plus (we only compute exponent value)\n",
    "        weight_mask_exp = weight_exp // (2**(8 - mask_value))\n",
    "        weight_exp_value, weight_exp_count = torch.unique(weight_mask_exp, return_counts=True)\n",
    "        print(\"==\"*20)\n",
    "        print(f\"{n} layer's weight exponent bit count (mask = {mask_value})\")\n",
    "        print()\n",
    "        print(\"total count: \", weight_tensor.numel())\n",
    "        value_count = 0\n",
    "        for wv, wc in zip(weight_exp_value, weight_exp_count):\n",
    "            print(\"{:05b} : {}\".format(wv, wc))\n",
    "            value_count += wc\n",
    "            \n",
    "        if not (weight_tensor.numel() - value_count) == 0:\n",
    "            print(\"# of number differ \", int(weight_tensor.numel()) - int(value_count))\n",
    "        print()\n",
    "        print(\"==\"*20)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864c0bd9",
   "metadata": {},
   "source": [
    "### resnet 50 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6da0896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/pdh/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e68c71f45e41ed8781617f63b2f37b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get pretrained net :  resnet50\n",
      "========================================\n",
      "conv1 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01011011 : 1\n",
      "01100000 : 3\n",
      "01100001 : 1\n",
      "01100010 : 9\n",
      "01100011 : 26\n",
      "01100100 : 70\n",
      "01100101 : 37\n",
      "01101101 : 1\n",
      "01101110 : 1\n",
      "01101111 : 2\n",
      "01110000 : 5\n",
      "01110001 : 12\n",
      "01110010 : 28\n",
      "01110011 : 45\n",
      "01110100 : 86\n",
      "01110101 : 203\n",
      "01110110 : 347\n",
      "01110111 : 683\n",
      "01111000 : 1127\n",
      "01111001 : 1512\n",
      "01111010 : 1716\n",
      "01111011 : 1624\n",
      "01111100 : 1255\n",
      "01111101 : 552\n",
      "01111110 : 62\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer1.0.conv1 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01011011 : 1\n",
      "01011100 : 1\n",
      "01011101 : 1\n",
      "01011110 : 6\n",
      "01011111 : 5\n",
      "01100000 : 13\n",
      "01100001 : 24\n",
      "01100010 : 45\n",
      "01100011 : 75\n",
      "01100100 : 108\n",
      "01100101 : 84\n",
      "01100110 : 16\n",
      "01101111 : 2\n",
      "01110000 : 2\n",
      "01110001 : 6\n",
      "01110010 : 13\n",
      "01110011 : 22\n",
      "01110100 : 50\n",
      "01110101 : 87\n",
      "01110110 : 172\n",
      "01110111 : 323\n",
      "01111000 : 589\n",
      "01111001 : 852\n",
      "01111010 : 845\n",
      "01111011 : 499\n",
      "01111100 : 187\n",
      "01111101 : 61\n",
      "01111110 : 7\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer1.0.conv2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01011000 : 2\n",
      "01011001 : 3\n",
      "01011010 : 3\n",
      "01011011 : 7\n",
      "01011100 : 12\n",
      "01011101 : 36\n",
      "01011110 : 54\n",
      "01011111 : 122\n",
      "01100000 : 239\n",
      "01100001 : 428\n",
      "01100010 : 902\n",
      "01100011 : 1297\n",
      "01100100 : 841\n",
      "01100101 : 139\n",
      "01100110 : 116\n",
      "01100111 : 161\n",
      "01101000 : 89\n",
      "01101001 : 20\n",
      "01101010 : 2\n",
      "01101100 : 5\n",
      "01101101 : 12\n",
      "01101110 : 14\n",
      "01101111 : 25\n",
      "01110000 : 60\n",
      "01110001 : 112\n",
      "01110010 : 233\n",
      "01110011 : 462\n",
      "01110100 : 844\n",
      "01110101 : 1445\n",
      "01110110 : 2642\n",
      "01110111 : 4976\n",
      "01111000 : 7806\n",
      "01111001 : 8010\n",
      "01111010 : 4308\n",
      "01111011 : 1175\n",
      "01111100 : 234\n",
      "01111101 : 28\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer1.0.conv3 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01011010 : 1\n",
      "01011011 : 1\n",
      "01011100 : 3\n",
      "01011110 : 12\n",
      "01011111 : 10\n",
      "01100000 : 31\n",
      "01100001 : 59\n",
      "01100010 : 128\n",
      "01100011 : 175\n",
      "01100100 : 191\n",
      "01100101 : 154\n",
      "01100110 : 198\n",
      "01100111 : 251\n",
      "01101000 : 221\n",
      "01101001 : 174\n",
      "01101010 : 124\n",
      "01101011 : 82\n",
      "01101100 : 59\n",
      "01101101 : 105\n",
      "01101110 : 87\n",
      "01101111 : 68\n",
      "01110000 : 90\n",
      "01110001 : 98\n",
      "01110010 : 147\n",
      "01110011 : 226\n",
      "01110100 : 420\n",
      "01110101 : 730\n",
      "01110110 : 1211\n",
      "01110111 : 1819\n",
      "01111000 : 2559\n",
      "01111001 : 3172\n",
      "01111010 : 2570\n",
      "01111011 : 1030\n",
      "01111100 : 161\n",
      "01111101 : 17\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer1.0.downsample.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01011010 : 2\n",
      "01011101 : 2\n",
      "01011110 : 3\n",
      "01011111 : 16\n",
      "01100000 : 20\n",
      "01100001 : 34\n",
      "01100010 : 86\n",
      "01100011 : 123\n",
      "01100100 : 110\n",
      "01100101 : 109\n",
      "01100110 : 185\n",
      "01100111 : 215\n",
      "01101000 : 162\n",
      "01101001 : 127\n",
      "01101010 : 123\n",
      "01101011 : 81\n",
      "01101100 : 76\n",
      "01101101 : 55\n",
      "01101110 : 47\n",
      "01101111 : 41\n",
      "01110000 : 54\n",
      "01110001 : 71\n",
      "01110010 : 121\n",
      "01110011 : 174\n",
      "01110100 : 254\n",
      "01110101 : 460\n",
      "01110110 : 870\n",
      "01110111 : 1606\n",
      "01111000 : 2624\n",
      "01111001 : 3236\n",
      "01111010 : 2897\n",
      "01111011 : 1715\n",
      "01111100 : 571\n",
      "01111101 : 102\n",
      "01111110 : 12\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer1.1.conv1 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01010110 : 1\n",
      "01011001 : 1\n",
      "01011011 : 2\n",
      "01011100 : 2\n",
      "01011101 : 2\n",
      "01011110 : 11\n",
      "01011111 : 18\n",
      "01100000 : 29\n",
      "01100001 : 79\n",
      "01100010 : 122\n",
      "01100011 : 209\n",
      "01100100 : 337\n",
      "01100101 : 286\n",
      "01100110 : 239\n",
      "01100111 : 270\n",
      "01101000 : 209\n",
      "01101001 : 131\n",
      "01101010 : 91\n",
      "01101011 : 65\n",
      "01101100 : 71\n",
      "01101101 : 90\n",
      "01101110 : 50\n",
      "01101111 : 55\n",
      "01110000 : 60\n",
      "01110001 : 67\n",
      "01110010 : 94\n",
      "01110011 : 164\n",
      "01110100 : 246\n",
      "01110101 : 500\n",
      "01110110 : 901\n",
      "01110111 : 1588\n",
      "01111000 : 2879\n",
      "01111001 : 3800\n",
      "01111010 : 2783\n",
      "01111011 : 861\n",
      "01111100 : 70\n",
      "01111101 : 1\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer1.1.conv2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01011001 : 1\n",
      "01011010 : 3\n",
      "01011011 : 6\n",
      "01011100 : 5\n",
      "01011101 : 22\n",
      "01011110 : 33\n",
      "01011111 : 68\n",
      "01100000 : 123\n",
      "01100001 : 246\n",
      "01100010 : 411\n",
      "01100011 : 566\n",
      "01100100 : 374\n",
      "01100101 : 140\n",
      "01100110 : 154\n",
      "01100111 : 111\n",
      "01101000 : 24\n",
      "01101001 : 11\n",
      "01101010 : 6\n",
      "01101011 : 1\n",
      "01101100 : 1\n",
      "01101101 : 5\n",
      "01101110 : 10\n",
      "01101111 : 18\n",
      "01110000 : 51\n",
      "01110001 : 71\n",
      "01110010 : 148\n",
      "01110011 : 304\n",
      "01110100 : 597\n",
      "01110101 : 1282\n",
      "01110110 : 2476\n",
      "01110111 : 4631\n",
      "01111000 : 8006\n",
      "01111001 : 9679\n",
      "01111010 : 5814\n",
      "01111011 : 1307\n",
      "01111100 : 154\n",
      "01111101 : 4\n",
      "01111110 : 1\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer1.1.conv3 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01011110 : 1\n",
      "01100000 : 1\n",
      "01100001 : 3\n",
      "01100010 : 1\n",
      "01100011 : 2\n",
      "01100100 : 7\n",
      "01100101 : 15\n",
      "01100110 : 24\n",
      "01100111 : 22\n",
      "01101000 : 20\n",
      "01101001 : 22\n",
      "01101010 : 26\n",
      "01101011 : 21\n",
      "01101100 : 44\n",
      "01101101 : 70\n",
      "01101110 : 59\n",
      "01101111 : 57\n",
      "01110000 : 75\n",
      "01110001 : 100\n",
      "01110010 : 157\n",
      "01110011 : 309\n",
      "01110100 : 604\n",
      "01110101 : 1158\n",
      "01110110 : 1883\n",
      "01110111 : 2293\n",
      "01111000 : 2675\n",
      "01111001 : 3070\n",
      "01111010 : 2583\n",
      "01111011 : 960\n",
      "01111100 : 117\n",
      "01111101 : 5\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer1.2.conv1 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01011010 : 1\n",
      "01011101 : 1\n",
      "01011111 : 2\n",
      "01100000 : 3\n",
      "01100001 : 1\n",
      "01100010 : 4\n",
      "01100011 : 6\n",
      "01100100 : 13\n",
      "01100101 : 24\n",
      "01100110 : 31\n",
      "01100111 : 30\n",
      "01101000 : 18\n",
      "01101001 : 27\n",
      "01101010 : 25\n",
      "01101011 : 35\n",
      "01101100 : 54\n",
      "01101101 : 50\n",
      "01101110 : 49\n",
      "01101111 : 47\n",
      "01110000 : 63\n",
      "01110001 : 54\n",
      "01110010 : 87\n",
      "01110011 : 170\n",
      "01110100 : 277\n",
      "01110101 : 557\n",
      "01110110 : 1053\n",
      "01110111 : 2031\n",
      "01111000 : 3452\n",
      "01111001 : 4274\n",
      "01111010 : 3084\n",
      "01111011 : 829\n",
      "01111100 : 32\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer1.2.conv2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101010 : 1\n",
      "01101011 : 2\n",
      "01101100 : 1\n",
      "01101101 : 2\n",
      "01101110 : 6\n",
      "01101111 : 17\n",
      "01110000 : 42\n",
      "01110001 : 67\n",
      "01110010 : 133\n",
      "01110011 : 280\n",
      "01110100 : 577\n",
      "01110101 : 1080\n",
      "01110110 : 2150\n",
      "01110111 : 4202\n",
      "01111000 : 7620\n",
      "01111001 : 10720\n",
      "01111010 : 7889\n",
      "01111011 : 1982\n",
      "01111100 : 92\n",
      "01111101 : 1\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer1.2.conv3 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101100 : 6\n",
      "01101101 : 5\n",
      "01101110 : 10\n",
      "01101111 : 19\n",
      "01110000 : 53\n",
      "01110001 : 86\n",
      "01110010 : 180\n",
      "01110011 : 364\n",
      "01110100 : 695\n",
      "01110101 : 1419\n",
      "01110110 : 2319\n",
      "01110111 : 2984\n",
      "01111000 : 2469\n",
      "01111001 : 2503\n",
      "01111010 : 2191\n",
      "01111011 : 958\n",
      "01111100 : 122\n",
      "01111101 : 1\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.0.conv1 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101101 : 2\n",
      "01101110 : 7\n",
      "01101111 : 19\n",
      "01110000 : 29\n",
      "01110001 : 59\n",
      "01110010 : 119\n",
      "01110011 : 267\n",
      "01110100 : 505\n",
      "01110101 : 1072\n",
      "01110110 : 2129\n",
      "01110111 : 4012\n",
      "01111000 : 6900\n",
      "01111001 : 8633\n",
      "01111010 : 6542\n",
      "01111011 : 2200\n",
      "01111100 : 264\n",
      "01111101 : 9\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.0.conv2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100111 : 1\n",
      "01101000 : 1\n",
      "01101001 : 1\n",
      "01101010 : 5\n",
      "01101011 : 7\n",
      "01101100 : 10\n",
      "01101101 : 19\n",
      "01101110 : 48\n",
      "01101111 : 88\n",
      "01110000 : 210\n",
      "01110001 : 378\n",
      "01110010 : 740\n",
      "01110011 : 1546\n",
      "01110100 : 3107\n",
      "01110101 : 6205\n",
      "01110110 : 12234\n",
      "01110111 : 23198\n",
      "01111000 : 38477\n",
      "01111001 : 41190\n",
      "01111010 : 17745\n",
      "01111011 : 2195\n",
      "01111100 : 49\n",
      "01111101 : 2\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.0.conv3 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01011100 : 1\n",
      "01011101 : 1\n",
      "01011110 : 10\n",
      "01011111 : 16\n",
      "01100000 : 25\n",
      "01100001 : 49\n",
      "01100010 : 113\n",
      "01100011 : 220\n",
      "01100100 : 321\n",
      "01100101 : 492\n",
      "01100110 : 573\n",
      "01100111 : 618\n",
      "01101000 : 766\n",
      "01101001 : 682\n",
      "01101010 : 619\n",
      "01101011 : 648\n",
      "01101100 : 593\n",
      "01101101 : 427\n",
      "01101110 : 392\n",
      "01101111 : 319\n",
      "01110000 : 286\n",
      "01110001 : 370\n",
      "01110010 : 589\n",
      "01110011 : 861\n",
      "01110100 : 1527\n",
      "01110101 : 2809\n",
      "01110110 : 5136\n",
      "01110111 : 9300\n",
      "01111000 : 13137\n",
      "01111001 : 13246\n",
      "01111010 : 8677\n",
      "01111011 : 2398\n",
      "01111100 : 299\n",
      "01111101 : 16\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.0.downsample.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01011001 : 1\n",
      "01011011 : 2\n",
      "01011100 : 7\n",
      "01011101 : 12\n",
      "01011110 : 11\n",
      "01011111 : 23\n",
      "01100000 : 78\n",
      "01100001 : 144\n",
      "01100010 : 275\n",
      "01100011 : 494\n",
      "01100100 : 807\n",
      "01100101 : 1029\n",
      "01100110 : 1056\n",
      "01100111 : 1159\n",
      "01101000 : 1424\n",
      "01101001 : 1464\n",
      "01101010 : 1307\n",
      "01101011 : 1370\n",
      "01101100 : 1030\n",
      "01101101 : 741\n",
      "01101110 : 727\n",
      "01101111 : 696\n",
      "01110000 : 625\n",
      "01110001 : 803\n",
      "01110010 : 1277\n",
      "01110011 : 1977\n",
      "01110100 : 3522\n",
      "01110101 : 6529\n",
      "01110110 : 12263\n",
      "01110111 : 21460\n",
      "01111000 : 30700\n",
      "01111001 : 25479\n",
      "01111010 : 9682\n",
      "01111011 : 2392\n",
      "01111100 : 466\n",
      "01111101 : 37\n",
      "01111110 : 3\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.1.conv1 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01011010 : 1\n",
      "01011011 : 2\n",
      "01011100 : 1\n",
      "01011101 : 5\n",
      "01011110 : 13\n",
      "01011111 : 17\n",
      "01100000 : 54\n",
      "01100001 : 100\n",
      "01100010 : 200\n",
      "01100011 : 392\n",
      "01100100 : 582\n",
      "01100101 : 596\n",
      "01100110 : 596\n",
      "01100111 : 730\n",
      "01101000 : 692\n",
      "01101001 : 732\n",
      "01101010 : 708\n",
      "01101011 : 568\n",
      "01101100 : 347\n",
      "01101101 : 352\n",
      "01101110 : 273\n",
      "01101111 : 240\n",
      "01110000 : 358\n",
      "01110001 : 520\n",
      "01110010 : 813\n",
      "01110011 : 1337\n",
      "01110100 : 2447\n",
      "01110101 : 4508\n",
      "01110110 : 8231\n",
      "01110111 : 12870\n",
      "01111000 : 14174\n",
      "01111001 : 9058\n",
      "01111010 : 3323\n",
      "01111011 : 645\n",
      "01111100 : 50\n",
      "01111101 : 1\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.1.conv2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100111 : 1\n",
      "01101001 : 3\n",
      "01101010 : 2\n",
      "01101011 : 15\n",
      "01101100 : 18\n",
      "01101101 : 43\n",
      "01101110 : 76\n",
      "01101111 : 145\n",
      "01110000 : 311\n",
      "01110001 : 663\n",
      "01110010 : 1311\n",
      "01110011 : 2561\n",
      "01110100 : 5127\n",
      "01110101 : 10214\n",
      "01110110 : 19191\n",
      "01110111 : 32283\n",
      "01111000 : 38830\n",
      "01111001 : 25143\n",
      "01111010 : 9283\n",
      "01111011 : 2009\n",
      "01111100 : 217\n",
      "01111101 : 10\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.1.conv3 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01011100 : 1\n",
      "01100001 : 1\n",
      "01100010 : 1\n",
      "01100011 : 1\n",
      "01100100 : 2\n",
      "01100101 : 3\n",
      "01100110 : 7\n",
      "01100111 : 10\n",
      "01101000 : 18\n",
      "01101001 : 51\n",
      "01101010 : 41\n",
      "01101011 : 14\n",
      "01101100 : 25\n",
      "01101101 : 60\n",
      "01101110 : 94\n",
      "01101111 : 192\n",
      "01110000 : 292\n",
      "01110001 : 524\n",
      "01110010 : 1007\n",
      "01110011 : 1741\n",
      "01110100 : 3354\n",
      "01110101 : 6218\n",
      "01110110 : 10530\n",
      "01110111 : 13529\n",
      "01111000 : 12371\n",
      "01111001 : 8875\n",
      "01111010 : 4894\n",
      "01111011 : 1478\n",
      "01111100 : 194\n",
      "01111101 : 8\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.2.conv1 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100001 : 1\n",
      "01100010 : 2\n",
      "01100011 : 1\n",
      "01100100 : 4\n",
      "01100101 : 5\n",
      "01100110 : 11\n",
      "01100111 : 14\n",
      "01101000 : 32\n",
      "01101001 : 43\n",
      "01101010 : 25\n",
      "01101011 : 24\n",
      "01101100 : 43\n",
      "01101101 : 68\n",
      "01101110 : 104\n",
      "01101111 : 129\n",
      "01110000 : 206\n",
      "01110001 : 290\n",
      "01110010 : 452\n",
      "01110011 : 816\n",
      "01110100 : 1572\n",
      "01110101 : 3024\n",
      "01110110 : 5791\n",
      "01110111 : 10739\n",
      "01111000 : 17109\n",
      "01111001 : 16790\n",
      "01111010 : 6796\n",
      "01111011 : 1301\n",
      "01111100 : 144\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.2.conv2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100110 : 3\n",
      "01101001 : 2\n",
      "01101010 : 3\n",
      "01101011 : 7\n",
      "01101100 : 19\n",
      "01101101 : 27\n",
      "01101110 : 59\n",
      "01101111 : 104\n",
      "01110000 : 209\n",
      "01110001 : 455\n",
      "01110010 : 861\n",
      "01110011 : 1728\n",
      "01110100 : 3501\n",
      "01110101 : 7058\n",
      "01110110 : 13616\n",
      "01110111 : 25808\n",
      "01111000 : 40454\n",
      "01111001 : 37226\n",
      "01111010 : 13796\n",
      "01111011 : 2378\n",
      "01111100 : 141\n",
      "01111101 : 1\n",
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "layer2.2.conv3 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101001 : 1\n",
      "01101010 : 2\n",
      "01101011 : 1\n",
      "01101100 : 8\n",
      "01101101 : 12\n",
      "01101110 : 22\n",
      "01101111 : 41\n",
      "01110000 : 90\n",
      "01110001 : 177\n",
      "01110010 : 329\n",
      "01110011 : 622\n",
      "01110100 : 1360\n",
      "01110101 : 2750\n",
      "01110110 : 5394\n",
      "01110111 : 9965\n",
      "01111000 : 16152\n",
      "01111001 : 17779\n",
      "01111010 : 8827\n",
      "01111011 : 1823\n",
      "01111100 : 175\n",
      "01111101 : 6\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.3.conv1 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101010 : 1\n",
      "01101011 : 3\n",
      "01101100 : 6\n",
      "01101101 : 13\n",
      "01101110 : 13\n",
      "01101111 : 36\n",
      "01110000 : 91\n",
      "01110001 : 179\n",
      "01110010 : 292\n",
      "01110011 : 630\n",
      "01110100 : 1318\n",
      "01110101 : 2498\n",
      "01110110 : 5098\n",
      "01110111 : 9713\n",
      "01111000 : 16300\n",
      "01111001 : 18648\n",
      "01111010 : 9294\n",
      "01111011 : 1350\n",
      "01111100 : 52\n",
      "01111101 : 1\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.3.conv2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100110 : 1\n",
      "01100111 : 1\n",
      "01101001 : 2\n",
      "01101010 : 1\n",
      "01101011 : 7\n",
      "01101100 : 9\n",
      "01101101 : 21\n",
      "01101110 : 33\n",
      "01101111 : 94\n",
      "01110000 : 189\n",
      "01110001 : 388\n",
      "01110010 : 745\n",
      "01110011 : 1534\n",
      "01110100 : 3001\n",
      "01110101 : 6012\n",
      "01110110 : 11661\n",
      "01110111 : 22405\n",
      "01111000 : 38116\n",
      "01111001 : 42376\n",
      "01111010 : 18768\n",
      "01111011 : 2059\n",
      "01111100 : 33\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer2.3.conv3 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100110 : 1\n",
      "01101000 : 1\n",
      "01101001 : 1\n",
      "01101010 : 2\n",
      "01101011 : 3\n",
      "01101100 : 6\n",
      "01101101 : 11\n",
      "01101110 : 29\n",
      "01101111 : 50\n",
      "01110000 : 93\n",
      "01110001 : 203\n",
      "01110010 : 415\n",
      "01110011 : 731\n",
      "01110100 : 1652\n",
      "01110101 : 3198\n",
      "01110110 : 6219\n",
      "01110111 : 11351\n",
      "01111000 : 16417\n",
      "01111001 : 15518\n",
      "01111010 : 7872\n",
      "01111011 : 1648\n",
      "01111100 : 110\n",
      "01111101 : 5\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.0.conv1 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101000 : 1\n",
      "01101001 : 1\n",
      "01101010 : 5\n",
      "01101011 : 5\n",
      "01101100 : 6\n",
      "01101101 : 19\n",
      "01101110 : 30\n",
      "01101111 : 53\n",
      "01110000 : 128\n",
      "01110001 : 255\n",
      "01110010 : 539\n",
      "01110011 : 1093\n",
      "01110100 : 2193\n",
      "01110101 : 4306\n",
      "01110110 : 8732\n",
      "01110111 : 16641\n",
      "01111000 : 29691\n",
      "01111001 : 37135\n",
      "01111010 : 23939\n",
      "01111011 : 5697\n",
      "01111100 : 576\n",
      "01111101 : 27\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.0.conv2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100001 : 1\n",
      "01100100 : 2\n",
      "01100110 : 1\n",
      "01100111 : 1\n",
      "01101000 : 7\n",
      "01101001 : 7\n",
      "01101010 : 18\n",
      "01101011 : 20\n",
      "01101100 : 66\n",
      "01101101 : 141\n",
      "01101110 : 241\n",
      "01101111 : 495\n",
      "01110000 : 992\n",
      "01110001 : 2040\n",
      "01110010 : 4002\n",
      "01110011 : 8171\n",
      "01110100 : 16250\n",
      "01110101 : 31920\n",
      "01110110 : 62888\n",
      "01110111 : 115320\n",
      "01111000 : 171157\n",
      "01111001 : 136560\n",
      "01111010 : 36010\n",
      "01111011 : 3383\n",
      "01111100 : 131\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.0.conv3 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01011110 : 1\n",
      "01011111 : 2\n",
      "01100000 : 5\n",
      "01100001 : 10\n",
      "01100010 : 21\n",
      "01100011 : 32\n",
      "01100100 : 69\n",
      "01100101 : 131\n",
      "01100110 : 244\n",
      "01100111 : 341\n",
      "01101000 : 472\n",
      "01101001 : 567\n",
      "01101010 : 748\n",
      "01101011 : 857\n",
      "01101100 : 926\n",
      "01101101 : 1016\n",
      "01101110 : 917\n",
      "01101111 : 1019\n",
      "01110000 : 1282\n",
      "01110001 : 1482\n",
      "01110010 : 2030\n",
      "01110011 : 3122\n",
      "01110100 : 5732\n",
      "01110101 : 10852\n",
      "01110110 : 20936\n",
      "01110111 : 39492\n",
      "01111000 : 63488\n",
      "01111001 : 68861\n",
      "01111010 : 32242\n",
      "01111011 : 4914\n",
      "01111100 : 326\n",
      "01111101 : 7\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.0.downsample.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01011011 : 1\n",
      "01011101 : 2\n",
      "01011110 : 2\n",
      "01011111 : 6\n",
      "01100000 : 14\n",
      "01100001 : 24\n",
      "01100010 : 49\n",
      "01100011 : 123\n",
      "01100100 : 224\n",
      "01100101 : 344\n",
      "01100110 : 517\n",
      "01100111 : 676\n",
      "01101000 : 993\n",
      "01101001 : 1476\n",
      "01101010 : 1856\n",
      "01101011 : 2040\n",
      "01101100 : 1963\n",
      "01101101 : 1729\n",
      "01101110 : 1521\n",
      "01101111 : 2096\n",
      "01110000 : 2803\n",
      "01110001 : 3642\n",
      "01110010 : 5095\n",
      "01110011 : 9115\n",
      "01110100 : 16822\n",
      "01110101 : 32462\n",
      "01110110 : 62645\n",
      "01110111 : 108774\n",
      "01111000 : 144152\n",
      "01111001 : 96205\n",
      "01111010 : 23597\n",
      "01111011 : 3052\n",
      "01111100 : 256\n",
      "01111101 : 12\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.1.conv1 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01010111 : 1\n",
      "01011010 : 1\n",
      "01011011 : 1\n",
      "01011100 : 1\n",
      "01011101 : 1\n",
      "01011110 : 5\n",
      "01011111 : 6\n",
      "01100000 : 13\n",
      "01100001 : 26\n",
      "01100010 : 38\n",
      "01100011 : 102\n",
      "01100100 : 187\n",
      "01100101 : 347\n",
      "01100110 : 427\n",
      "01100111 : 625\n",
      "01101000 : 771\n",
      "01101001 : 832\n",
      "01101010 : 933\n",
      "01101011 : 1043\n",
      "01101100 : 864\n",
      "01101101 : 807\n",
      "01101110 : 1075\n",
      "01101111 : 1103\n",
      "01110000 : 1175\n",
      "01110001 : 1527\n",
      "01110010 : 2650\n",
      "01110011 : 4602\n",
      "01110100 : 8774\n",
      "01110101 : 17043\n",
      "01110110 : 32012\n",
      "01110111 : 54854\n",
      "01111000 : 70227\n",
      "01111001 : 48184\n",
      "01111010 : 10890\n",
      "01111011 : 919\n",
      "01111100 : 73\n",
      "01111101 : 5\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.1.conv2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100100 : 1\n",
      "01100110 : 3\n",
      "01101000 : 8\n",
      "01101001 : 9\n",
      "01101010 : 20\n",
      "01101011 : 35\n",
      "01101100 : 69\n",
      "01101101 : 149\n",
      "01101110 : 309\n",
      "01101111 : 604\n",
      "01110000 : 1172\n",
      "01110001 : 2363\n",
      "01110010 : 4677\n",
      "01110011 : 9288\n",
      "01110100 : 18574\n",
      "01110101 : 37242\n",
      "01110110 : 71772\n",
      "01110111 : 130120\n",
      "01111000 : 176094\n",
      "01111001 : 112164\n",
      "01111010 : 22887\n",
      "01111011 : 2176\n",
      "01111100 : 87\n",
      "01111101 : 1\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.1.conv3 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100100 : 3\n",
      "01100101 : 2\n",
      "01100110 : 7\n",
      "01100111 : 15\n",
      "01101000 : 31\n",
      "01101001 : 31\n",
      "01101010 : 86\n",
      "01101011 : 147\n",
      "01101100 : 223\n",
      "01101101 : 260\n",
      "01101110 : 347\n",
      "01101111 : 293\n",
      "01110000 : 459\n",
      "01110001 : 883\n",
      "01110010 : 1686\n",
      "01110011 : 3347\n",
      "01110100 : 6526\n",
      "01110101 : 12909\n",
      "01110110 : 24907\n",
      "01110111 : 46670\n",
      "01111000 : 70890\n",
      "01111001 : 66757\n",
      "01111010 : 22770\n",
      "01111011 : 2635\n",
      "01111100 : 248\n",
      "01111101 : 12\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.2.conv1 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100011 : 1\n",
      "01100100 : 7\n",
      "01100101 : 5\n",
      "01100110 : 12\n",
      "01100111 : 27\n",
      "01101000 : 45\n",
      "01101001 : 96\n",
      "01101010 : 182\n",
      "01101011 : 269\n",
      "01101100 : 281\n",
      "01101101 : 230\n",
      "01101110 : 199\n",
      "01101111 : 301\n",
      "01110000 : 620\n",
      "01110001 : 1020\n",
      "01110010 : 2078\n",
      "01110011 : 4105\n",
      "01110100 : 8262\n",
      "01110101 : 16603\n",
      "01110110 : 31900\n",
      "01110111 : 55909\n",
      "01111000 : 76917\n",
      "01111001 : 51000\n",
      "01111010 : 10657\n",
      "01111011 : 1331\n",
      "01111100 : 86\n",
      "01111101 : 1\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.2.conv2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100110 : 2\n",
      "01100111 : 4\n",
      "01101000 : 5\n",
      "01101001 : 4\n",
      "01101010 : 18\n",
      "01101011 : 32\n",
      "01101100 : 67\n",
      "01101101 : 128\n",
      "01101110 : 289\n",
      "01101111 : 549\n",
      "01110000 : 1156\n",
      "01110001 : 2234\n",
      "01110010 : 4441\n",
      "01110011 : 8651\n",
      "01110100 : 17698\n",
      "01110101 : 35402\n",
      "01110110 : 68472\n",
      "01110111 : 125444\n",
      "01111000 : 178383\n",
      "01111001 : 122062\n",
      "01111010 : 23272\n",
      "01111011 : 1463\n",
      "01111100 : 48\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.2.conv3 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100101 : 1\n",
      "01100110 : 3\n",
      "01100111 : 4\n",
      "01101000 : 8\n",
      "01101001 : 14\n",
      "01101010 : 25\n",
      "01101011 : 60\n",
      "01101100 : 76\n",
      "01101101 : 141\n",
      "01101110 : 136\n",
      "01101111 : 206\n",
      "01110000 : 433\n",
      "01110001 : 863\n",
      "01110010 : 1734\n",
      "01110011 : 3486\n",
      "01110100 : 6854\n",
      "01110101 : 13026\n",
      "01110110 : 26098\n",
      "01110111 : 48126\n",
      "01111000 : 73219\n",
      "01111001 : 64756\n",
      "01111010 : 20631\n",
      "01111011 : 2112\n",
      "01111100 : 127\n",
      "01111101 : 5\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.3.conv1 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100010 : 1\n",
      "01100011 : 1\n",
      "01100100 : 1\n",
      "01100101 : 2\n",
      "01100110 : 2\n",
      "01100111 : 7\n",
      "01101000 : 19\n",
      "01101001 : 35\n",
      "01101010 : 70\n",
      "01101011 : 107\n",
      "01101100 : 56\n",
      "01101101 : 62\n",
      "01101110 : 112\n",
      "01101111 : 200\n",
      "01110000 : 429\n",
      "01110001 : 887\n",
      "01110010 : 1791\n",
      "01110011 : 3494\n",
      "01110100 : 7050\n",
      "01110101 : 13983\n",
      "01110110 : 27494\n",
      "01110111 : 50101\n",
      "01111000 : 76381\n",
      "01111001 : 63181\n",
      "01111010 : 15203\n",
      "01111011 : 1388\n",
      "01111100 : 87\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.3.conv2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100111 : 2\n",
      "01101000 : 9\n",
      "01101001 : 6\n",
      "01101010 : 9\n",
      "01101011 : 27\n",
      "01101100 : 72\n",
      "01101101 : 131\n",
      "01101110 : 245\n",
      "01101111 : 522\n",
      "01110000 : 1078\n",
      "01110001 : 2188\n",
      "01110010 : 4215\n",
      "01110011 : 8671\n",
      "01110100 : 16926\n",
      "01110101 : 33759\n",
      "01110110 : 66263\n",
      "01110111 : 122838\n",
      "01111000 : 179260\n",
      "01111001 : 129667\n",
      "01111010 : 22927\n",
      "01111011 : 991\n",
      "01111100 : 17\n",
      "01111101 : 1\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.3.conv3 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100010 : 1\n",
      "01100100 : 3\n",
      "01100101 : 2\n",
      "01100110 : 2\n",
      "01100111 : 5\n",
      "01101000 : 9\n",
      "01101001 : 14\n",
      "01101010 : 24\n",
      "01101011 : 57\n",
      "01101100 : 116\n",
      "01101101 : 103\n",
      "01101110 : 131\n",
      "01101111 : 203\n",
      "01110000 : 446\n",
      "01110001 : 870\n",
      "01110010 : 1747\n",
      "01110011 : 3536\n",
      "01110100 : 7072\n",
      "01110101 : 14144\n",
      "01110110 : 27348\n",
      "01110111 : 49531\n",
      "01111000 : 72406\n",
      "01111001 : 63309\n",
      "01111010 : 19434\n",
      "01111011 : 1560\n",
      "01111100 : 66\n",
      "01111101 : 5\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.4.conv1 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100101 : 2\n",
      "01100110 : 3\n",
      "01100111 : 6\n",
      "01101000 : 15\n",
      "01101001 : 28\n",
      "01101010 : 69\n",
      "01101011 : 92\n",
      "01101100 : 68\n",
      "01101101 : 63\n",
      "01101110 : 89\n",
      "01101111 : 221\n",
      "01110000 : 411\n",
      "01110001 : 791\n",
      "01110010 : 1596\n",
      "01110011 : 3236\n",
      "01110100 : 6315\n",
      "01110101 : 12948\n",
      "01110110 : 25228\n",
      "01110111 : 47628\n",
      "01111000 : 75016\n",
      "01111001 : 68727\n",
      "01111010 : 18098\n",
      "01111011 : 1401\n",
      "01111100 : 91\n",
      "01111101 : 2\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.4.conv2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100110 : 2\n",
      "01101000 : 5\n",
      "01101001 : 10\n",
      "01101010 : 23\n",
      "01101011 : 27\n",
      "01101100 : 75\n",
      "01101101 : 155\n",
      "01101110 : 264\n",
      "01101111 : 549\n",
      "01110000 : 1046\n",
      "01110001 : 2127\n",
      "01110010 : 4385\n",
      "01110011 : 8615\n",
      "01110100 : 16997\n",
      "01110101 : 33604\n",
      "01110110 : 66205\n",
      "01110111 : 122459\n",
      "01111000 : 179401\n",
      "01111001 : 130421\n",
      "01111010 : 22490\n",
      "01111011 : 947\n",
      "01111100 : 17\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.4.conv3 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100111 : 1\n",
      "01101000 : 1\n",
      "01101001 : 2\n",
      "01101010 : 4\n",
      "01101011 : 10\n",
      "01101100 : 29\n",
      "01101101 : 52\n",
      "01101110 : 114\n",
      "01101111 : 226\n",
      "01110000 : 490\n",
      "01110001 : 908\n",
      "01110010 : 1805\n",
      "01110011 : 3611\n",
      "01110100 : 7273\n",
      "01110101 : 14438\n",
      "01110110 : 27922\n",
      "01110111 : 49503\n",
      "01111000 : 72223\n",
      "01111001 : 62602\n",
      "01111010 : 19224\n",
      "01111011 : 1620\n",
      "01111100 : 85\n",
      "01111101 : 1\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.5.conv1 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01101010 : 3\n",
      "01101011 : 14\n",
      "01101100 : 18\n",
      "01101101 : 55\n",
      "01101110 : 74\n",
      "01101111 : 158\n",
      "01110000 : 373\n",
      "01110001 : 739\n",
      "01110010 : 1389\n",
      "01110011 : 2824\n",
      "01110100 : 5802\n",
      "01110101 : 11528\n",
      "01110110 : 22829\n",
      "01110111 : 43111\n",
      "01111000 : 72425\n",
      "01111001 : 75183\n",
      "01111010 : 23752\n",
      "01111011 : 1774\n",
      "01111100 : 88\n",
      "01111101 : 5\n",
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "layer3.5.conv2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100100 : 1\n",
      "01100101 : 1\n",
      "01100110 : 2\n",
      "01100111 : 4\n",
      "01101000 : 1\n",
      "01101001 : 5\n",
      "01101010 : 16\n",
      "01101011 : 34\n",
      "01101100 : 61\n",
      "01101101 : 137\n",
      "01101110 : 249\n",
      "01101111 : 504\n",
      "01110000 : 1018\n",
      "01110001 : 2049\n",
      "01110010 : 4118\n",
      "01110011 : 8367\n",
      "01110100 : 16676\n",
      "01110101 : 32857\n",
      "01110110 : 64799\n",
      "01110111 : 119366\n",
      "01111000 : 178482\n",
      "01111001 : 135944\n",
      "01111010 : 24029\n",
      "01111011 : 1076\n",
      "01111100 : 28\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer3.5.conv3 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100110 : 1\n",
      "01100111 : 2\n",
      "01101001 : 2\n",
      "01101010 : 9\n",
      "01101011 : 9\n",
      "01101100 : 30\n",
      "01101101 : 45\n",
      "01101110 : 102\n",
      "01101111 : 208\n",
      "01110000 : 407\n",
      "01110001 : 836\n",
      "01110010 : 1609\n",
      "01110011 : 3280\n",
      "01110100 : 6691\n",
      "01110101 : 13362\n",
      "01110110 : 25494\n",
      "01110111 : 46228\n",
      "01111000 : 70575\n",
      "01111001 : 67830\n",
      "01111010 : 23543\n",
      "01111011 : 1809\n",
      "01111100 : 68\n",
      "01111101 : 4\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer4.0.conv1 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100111 : 2\n",
      "01101000 : 5\n",
      "01101001 : 3\n",
      "01101010 : 7\n",
      "01101011 : 22\n",
      "01101100 : 30\n",
      "01101101 : 75\n",
      "01101110 : 169\n",
      "01101111 : 277\n",
      "01110000 : 575\n",
      "01110001 : 1144\n",
      "01110010 : 2333\n",
      "01110011 : 4652\n",
      "01110100 : 9250\n",
      "01110101 : 18364\n",
      "01110110 : 36980\n",
      "01110111 : 71566\n",
      "01111000 : 127074\n",
      "01111001 : 163074\n",
      "01111010 : 80943\n",
      "01111011 : 7542\n",
      "01111100 : 195\n",
      "01111101 : 6\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer4.0.conv2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100010 : 1\n",
      "01100101 : 2\n",
      "01100110 : 5\n",
      "01100111 : 8\n",
      "01101000 : 22\n",
      "01101001 : 39\n",
      "01101010 : 66\n",
      "01101011 : 163\n",
      "01101100 : 310\n",
      "01101101 : 646\n",
      "01101110 : 1256\n",
      "01101111 : 2335\n",
      "01110000 : 4861\n",
      "01110001 : 9515\n",
      "01110010 : 19462\n",
      "01110011 : 38552\n",
      "01110100 : 76614\n",
      "01110101 : 151879\n",
      "01110110 : 297616\n",
      "01110111 : 540316\n",
      "01111000 : 745577\n",
      "01111001 : 430400\n",
      "01111010 : 39035\n",
      "01111011 : 591\n",
      "01111100 : 16\n",
      "01111101 : 9\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer4.0.conv3 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100101 : 2\n",
      "01100110 : 2\n",
      "01100111 : 3\n",
      "01101000 : 15\n",
      "01101001 : 15\n",
      "01101010 : 33\n",
      "01101011 : 53\n",
      "01101100 : 108\n",
      "01101101 : 218\n",
      "01101110 : 463\n",
      "01101111 : 907\n",
      "01110000 : 1813\n",
      "01110001 : 3718\n",
      "01110010 : 7441\n",
      "01110011 : 14712\n",
      "01110100 : 29299\n",
      "01110101 : 58115\n",
      "01110110 : 113611\n",
      "01110111 : 212142\n",
      "01111000 : 319066\n",
      "01111001 : 242575\n",
      "01111010 : 42279\n",
      "01111011 : 1912\n",
      "01111100 : 65\n",
      "01111101 : 9\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer4.0.downsample.0 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100100 : 2\n",
      "01100101 : 4\n",
      "01100110 : 5\n",
      "01100111 : 11\n",
      "01101000 : 16\n",
      "01101001 : 43\n",
      "01101010 : 79\n",
      "01101011 : 189\n",
      "01101100 : 367\n",
      "01101101 : 687\n",
      "01101110 : 1433\n",
      "01101111 : 2909\n",
      "01110000 : 5851\n",
      "01110001 : 11501\n",
      "01110010 : 23177\n",
      "01110011 : 46421\n",
      "01110100 : 92107\n",
      "01110101 : 182254\n",
      "01110110 : 347597\n",
      "01110111 : 575364\n",
      "01111000 : 597858\n",
      "01111001 : 195583\n",
      "01111010 : 12972\n",
      "01111011 : 639\n",
      "01111100 : 68\n",
      "01111101 : 14\n",
      "01111110 : 1\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer4.1.conv1 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100110 : 3\n",
      "01100111 : 2\n",
      "01101000 : 8\n",
      "01101001 : 18\n",
      "01101010 : 20\n",
      "01101011 : 55\n",
      "01101100 : 122\n",
      "01101101 : 215\n",
      "01101110 : 471\n",
      "01101111 : 929\n",
      "01110000 : 1888\n",
      "01110001 : 3689\n",
      "01110010 : 7415\n",
      "01110011 : 14610\n",
      "01110100 : 29386\n",
      "01110101 : 58818\n",
      "01110110 : 115553\n",
      "01110111 : 214274\n",
      "01111000 : 322504\n",
      "01111001 : 240365\n",
      "01111010 : 37221\n",
      "01111011 : 978\n",
      "01111100 : 22\n",
      "01111101 : 9\n",
      "01111110 : 1\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer4.1.conv2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100100 : 2\n",
      "01100101 : 2\n",
      "01100110 : 4\n",
      "01100111 : 12\n",
      "01101000 : 13\n",
      "01101001 : 39\n",
      "01101010 : 66\n",
      "01101011 : 150\n",
      "01101100 : 293\n",
      "01101101 : 614\n",
      "01101110 : 1187\n",
      "01101111 : 2376\n",
      "01110000 : 4739\n",
      "01110001 : 9557\n",
      "01110010 : 19266\n",
      "01110011 : 38379\n",
      "01110100 : 76281\n",
      "01110101 : 152334\n",
      "01110110 : 296670\n",
      "01110111 : 540161\n",
      "01111000 : 753688\n",
      "01111001 : 432084\n",
      "01111010 : 30940\n",
      "01111011 : 403\n",
      "01111100 : 36\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer4.1.conv3 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100110 : 3\n",
      "01100111 : 6\n",
      "01101000 : 6\n",
      "01101001 : 14\n",
      "01101010 : 18\n",
      "01101011 : 66\n",
      "01101100 : 104\n",
      "01101101 : 231\n",
      "01101110 : 461\n",
      "01101111 : 931\n",
      "01110000 : 1924\n",
      "01110001 : 3778\n",
      "01110010 : 7530\n",
      "01110011 : 14834\n",
      "01110100 : 30028\n",
      "01110101 : 59109\n",
      "01110110 : 116839\n",
      "01110111 : 215006\n",
      "01111000 : 319215\n",
      "01111001 : 237303\n",
      "01111010 : 39652\n",
      "01111011 : 1468\n",
      "01111100 : 50\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer4.2.conv1 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100100 : 1\n",
      "01100101 : 1\n",
      "01100110 : 2\n",
      "01100111 : 2\n",
      "01101000 : 8\n",
      "01101001 : 13\n",
      "01101010 : 17\n",
      "01101011 : 47\n",
      "01101100 : 86\n",
      "01101101 : 189\n",
      "01101110 : 361\n",
      "01101111 : 695\n",
      "01110000 : 1548\n",
      "01110001 : 3056\n",
      "01110010 : 5875\n",
      "01110011 : 12044\n",
      "01110100 : 24085\n",
      "01110101 : 47179\n",
      "01110110 : 93820\n",
      "01110111 : 178253\n",
      "01111000 : 296117\n",
      "01111001 : 300341\n",
      "01111010 : 81952\n",
      "01111011 : 2818\n",
      "01111100 : 60\n",
      "01111101 : 6\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer4.2.conv2 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100010 : 2\n",
      "01100101 : 3\n",
      "01100110 : 8\n",
      "01100111 : 9\n",
      "01101000 : 21\n",
      "01101001 : 53\n",
      "01101010 : 80\n",
      "01101011 : 175\n",
      "01101100 : 299\n",
      "01101101 : 684\n",
      "01101110 : 1343\n",
      "01101111 : 2610\n",
      "01110000 : 5314\n",
      "01110001 : 10680\n",
      "01110010 : 21223\n",
      "01110011 : 42532\n",
      "01110100 : 85049\n",
      "01110101 : 168905\n",
      "01110110 : 326662\n",
      "01110111 : 581988\n",
      "01111000 : 751116\n",
      "01111001 : 344455\n",
      "01111010 : 16019\n",
      "01111011 : 62\n",
      "01111100 : 4\n",
      "\n",
      "========================================\n",
      "========================================\n",
      "layer4.2.conv3 layer's weight exponent bit count\n",
      "zero count : 0\n",
      "\n",
      "01100011 : 1\n",
      "01100101 : 1\n",
      "01100111 : 8\n",
      "01101000 : 8\n",
      "01101001 : 19\n",
      "01101010 : 38\n",
      "01101011 : 69\n",
      "01101100 : 121\n",
      "01101101 : 244\n",
      "01101110 : 506\n",
      "01101111 : 1047\n",
      "01110000 : 2176\n",
      "01110001 : 4216\n",
      "01110010 : 8411\n",
      "01110011 : 16576\n",
      "01110100 : 33222\n",
      "01110101 : 66571\n",
      "01110110 : 128458\n",
      "01110111 : 231553\n",
      "01111000 : 319725\n",
      "01111001 : 201393\n",
      "01111010 : 31991\n",
      "01111011 : 2136\n",
      "01111100 : 81\n",
      "01111101 : 5\n",
      "\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "net_name = 'resnet50'\n",
    "\n",
    "if hasattr(models, net_name):\n",
    "    net = getattr(models, net_name)(pretrained=True)\n",
    "    print(f\"get pretrained net :  {net_name}\")\n",
    "else:\n",
    "    print(f\"model is not exist {net_name}\")\n",
    "\n",
    "for i, (n, m) in enumerate(net.named_modules()):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        weight_tensor = m.weight.data.flatten()\n",
    "        weight_exp = weight_tensor.view(torch.int32)\n",
    "        weight_exp = torch.div(weight_exp, (2**23), rounding_mode='floor')\n",
    "        weight_exp[weight_exp<0] += 256 # - value to plus\n",
    "        weight_exp_value, weight_exp_count = torch.unique(weight_exp, return_counts=True)\n",
    "        weight_zero_count = (weight_tensor == 0).sum()\n",
    "        print(\"==\"*20)\n",
    "        print(f\"{n} layer's weight exponent bit count\")\n",
    "        print(f\"zero count : {weight_zero_count}\")\n",
    "        print()\n",
    "        for wv, wc in zip(weight_exp_value, weight_exp_count):\n",
    "            print(\"{:08b} : {}\".format(wv, wc))\n",
    "        print()\n",
    "        print(\"==\"*20)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa570e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
